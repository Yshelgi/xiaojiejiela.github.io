{"pages":[{}],"posts":[{"title":"我想说的","date":"2020-03-29T09:28:33.000Z","path":"2020/03/29/我想说的/","text":"我们到底应该怎么去看待父母爷爷小时候教我三字经的时候就说要孝顺父母，但是现在是二十一世纪，一个物质社会，人与人之间的竞争逐渐牵涉到了家庭经济实力的竞争。从小学上课外兴趣班开始，教育投资就是家庭支出的一大笔花费。或者这样说同等学习能力的情况下，花钱越多请的老师越好的情况下，相应的学到的也会越多。这也就是为什么以前总是寒门出状元，而现在往往成绩好的孩子家庭条件也相应地很好。家庭条件好的家庭往往父母受教育程度也会更高，对教育有更好的方法，而且也有能力为孩子的兴趣爱好买单，而条件一般的家庭很多孩子的天赋只能被埋没。 我为什么会想到聊这个话题？你们也许只是知道我家庭关系不太好，但是知道到底有多差吗？我为什么这么讨厌我的爸爸你们永远你也体会不到。人总说家丑不可外扬，但是一直憋在我心里我也很难受，我学习或者做题的时候脑子里想到这些就会心情变差，所以我想把一些事说出来。我的爸爸是一个什么样的人呢 未满50岁，手脚健全，有工作能力但不去工作的无业游民 每天在家玩手机或者就是出去闲逛，不按时做饭的家长 脾气暴躁的偏执狂，总想着别人什么都听他的，一言不合就发脾气的精神病 从我记事开始，我的玩具或者学习用品就没有什么是他买的，他也不怎么管我；到了慢慢大点，我会开始思考，会开始规划人生未来，思考社会的时候，我发现他完全就是我最不想成为的那种人，但是我当时却像极了他，古怪的脾气懒惰的个性。于是我决定要开始改变自己，就算内在无法改变，但是表面上我还是要变得更好的，所以也许你们认识的我没有那么怪异，但是我还是会有控制不住自己的时候，也许基因的能力就是这么强大。 现状最近就是每天把自己关在房间里学习或者休息，不是必要的话不会出房间，可以这样说吧，除去出门拿快递和洗澡之类的，我基本上都是在我房间呆着，不愿意去和他接触。昨天和一个朋友偶然聊到结婚这个话题，进而聊到了男生是不是结婚需要有房有车，她说男生现在结婚不都有房有车吗？我说啊？现在人赚钱这么轻松吗？她说父母都会给的啊，我顿时心里就被刺了一下，回头想想，确实。 我家也有几套房，要是我结婚房车应该不是问题，但是这些只是我父母的，我不喜欢他们，所以我也不想欠他们更多，我承认他们赋予我生命，抚养我长这么大付出很多，但是我确实不喜欢他们，这也就导致了越长大我就越不愿意花他们的钱。因此，我也就说了30岁之前不结婚的话，如果未来的房车不是我自己赚来的，那我是不会结婚的。 最后不是每个人都和父母相处成仇人，一般都是比较冷淡起码不会有太大矛盾，即使他们原谅了我，我也不会原谅他们。这不是孝不孝顺的问题，我的生活，心理全部因为他们变得很差很差，我的身体状况也好不起来，从小就是鬼门关来回的人，他们从来不会在你需要的时候出现，甚至会故意的为难你（初中我左脚骨折，我妈甩给我两百块自己一只脚蹦去医院，后来蹦着上学放学，导致我右脚膝盖当时就磨损严重了，到了高中右膝半月板也出了问题……又或者是再小一点，因为我吃饭吃得慢所以把一个三岁的小孩大半夜的推出家门外，一个人在漆黑的楼梯里），我为什么要喜欢他们？出生就有哮喘鼻炎，然后长大过程中各种大病小病，我现在能运动，能健康的活着都是靠着我自己的努力，我知道我要活着，所以我开始多吃饭不挑食，会自己给自己做饭吃，锻炼肺活量，遇到什么我都习惯了自己去处理，习惯了不依赖其他人，当然我也不那么信任其他人。 一个男人，如果手脚健全没伤没病，呆在家里耗日子，也不会去照顾家庭，那他的一辈子也就那样了。不管是对我以后生活工作，还是对我以后教育孩子都是很好的反面例子，也许我本来没什么优点，但是经历多了之后，自然就有了优点。我会一直努力，为的是我能彻底不再需要他们，为的是能自己拥有自己的新生活，为的是我的儿子不会讨厌我而是尊敬崇拜我，为的是我能实现我的梦想，为的是不会成为他。 我希望在二十一世纪的每个孩子记住一句话，如果你觉得你的父母给你的不够多（物质方面或者是精神方面），这并没有错，不要再活在过去的愚孝中了，不满没什么不好说的，大胆的把自己内心的不满宣泄出来反而会更好过。不过最重要的是说出来之后，你要想着如何做好自己，让自己未来不会变成他们的样子。","content":"<h1 id=\"我们到底应该怎么去看待父母\"><a href=\"#我们到底应该怎么去看待父母\" class=\"headerlink\" title=\"我们到底应该怎么去看待父母\"></a>我们到底应该怎么去看待父母</h1><p>爷爷小时候教我三字经的时候就说要孝顺父母，但是现在是二十一世纪，一个物质社会，人与人之间的竞争逐渐牵涉到了家庭经济实力的竞争。从小学上课外兴趣班开始，教育投资就是家庭支出的一大笔花费。或者这样说同等学习能力的情况下，花钱越多请的老师越好的情况下，相应的学到的也会越多。这也就是为什么以前总是寒门出状元，而现在往往成绩好的孩子家庭条件也相应地很好。家庭条件好的家庭往往父母受教育程度也会更高，对教育有更好的方法，而且也有能力为孩子的兴趣爱好买单，而条件一般的家庭很多孩子的天赋只能被埋没。</p>\n<a id=\"more\"></a>\n\n<h2 id=\"我为什么会想到聊这个话题？\"><a href=\"#我为什么会想到聊这个话题？\" class=\"headerlink\" title=\"我为什么会想到聊这个话题？\"></a>我为什么会想到聊这个话题？</h2><p>你们也许只是知道我家庭关系不太好，但是知道到底有多差吗？我为什么这么讨厌我的爸爸你们永远你也体会不到。人总说家丑不可外扬，但是一直憋在我心里我也很难受，我学习或者做题的时候脑子里想到这些就会心情变差，所以我想把一些事说出来。我的爸爸是一个什么样的人呢</p>\n<ul>\n<li>未满50岁，手脚健全，有工作能力但不去工作的无业游民</li>\n<li>每天在家玩手机或者就是出去闲逛，不按时做饭的家长</li>\n<li>脾气暴躁的偏执狂，总想着别人什么都听他的，一言不合就发脾气的精神病</li>\n</ul>\n<p>从我记事开始，我的玩具或者学习用品就没有什么是他买的，他也不怎么管我；到了慢慢大点，我会开始思考，会开始规划人生未来，思考社会的时候，我发现他完全就是我最不想成为的那种人，但是我当时却像极了他，古怪的脾气懒惰的个性。于是我决定要开始改变自己，就算内在无法改变，但是表面上我还是要变得更好的，所以也许你们认识的我没有那么怪异，但是我还是会有控制不住自己的时候，也许基因的能力就是这么强大。</p>\n<h2 id=\"现状\"><a href=\"#现状\" class=\"headerlink\" title=\"现状\"></a>现状</h2><p>最近就是每天把自己关在房间里学习或者休息，不是必要的话不会出房间，可以这样说吧，除去出门拿快递和洗澡之类的，我基本上都是在我房间呆着，不愿意去和他接触。昨天和一个朋友偶然聊到结婚这个话题，进而聊到了男生是不是结婚需要有房有车，她说男生现在结婚不都有房有车吗？我说啊？现在人赚钱这么轻松吗？她说父母都会给的啊，我顿时心里就被刺了一下，回头想想，确实。</p>\n<p><img src=\"/2020/03/29/%E6%88%91%E6%83%B3%E8%AF%B4%E7%9A%84/Screenshot_2020_0329_170854.png\" alt=\"聊天记录\"></p>\n<p>我家也有几套房，要是我结婚房车应该不是问题，但是这些只是我父母的，我不喜欢他们，所以我也不想欠他们更多，我承认他们赋予我生命，抚养我长这么大付出很多，但是我确实不喜欢他们，这也就导致了越长大我就越不愿意花他们的钱。因此，我也就说了30岁之前不结婚的话，如果未来的房车不是我自己赚来的，那我是不会结婚的。</p>\n<h2 id=\"最后\"><a href=\"#最后\" class=\"headerlink\" title=\"最后\"></a>最后</h2><p>不是每个人都和父母相处成仇人，一般都是比较冷淡起码不会有太大矛盾，即使他们原谅了我，我也不会原谅他们。这不是孝不孝顺的问题，我的生活，心理全部因为他们变得很差很差，我的身体状况也好不起来，从小就是鬼门关来回的人，他们从来不会在你需要的时候出现，甚至会故意的为难你（初中我左脚骨折，我妈甩给我两百块自己一只脚蹦去医院，后来蹦着上学放学，导致我右脚膝盖当时就磨损严重了，到了高中右膝半月板也出了问题……又或者是再小一点，因为我吃饭吃得慢所以把一个三岁的小孩大半夜的推出家门外，一个人在漆黑的楼梯里），我为什么要喜欢他们？出生就有哮喘鼻炎，然后长大过程中各种大病小病，我现在能运动，能健康的活着都是靠着我自己的努力，我知道我要活着，所以我开始多吃饭不挑食，会自己给自己做饭吃，锻炼肺活量，遇到什么我都习惯了自己去处理，习惯了不依赖其他人，当然我也不那么信任其他人。</p>\n<p>一个男人，如果手脚健全没伤没病，呆在家里耗日子，也不会去照顾家庭，那他的一辈子也就那样了。不管是对我以后生活工作，还是对我以后教育孩子都是很好的反面例子，也许我本来没什么优点，但是经历多了之后，自然就有了优点。我会一直努力，为的是我能彻底不再需要他们，为的是能自己拥有自己的新生活，为的是我的儿子不会讨厌我而是尊敬崇拜我，为的是我能实现我的梦想，为的是不会成为他。</p>\n<p>我希望在二十一世纪的每个孩子记住一句话，如果你觉得你的父母给你的不够多（物质方面或者是精神方面），这并没有错，不要再活在过去的愚孝中了，不满没什么不好说的，大胆的把自己内心的不满宣泄出来反而会更好过。不过最重要的是说出来之后，你要想着如何做好自己，让自己未来不会变成他们的样子。</p>\n","comments":true,"tags":[{"name":"我想说的","slug":"我想说的","permalink":"http://yoursite.com/tags/%E6%88%91%E6%83%B3%E8%AF%B4%E7%9A%84/"}]},{"title":"关于自杀数据集的分析","date":"2020-03-25T16:53:36.000Z","path":"2020/03/26/关于自杀数据集的分析/","text":"前言究竟是什么让我凌晨四点一边看着人家吃美食，一边敲代码，写博客，原因呢就是需要帮别人做这次的数据分析。 数据分析的背景来自于kaggle的一次比赛点这里去查看/下载数据关于数据集的介绍等下在代码中可以看到，这里就不多说了。这次竞赛就是通过一系列特征来找到自杀率上升的信号（也就是影响自杀率的因素） 开始数据分析1.导库、导数据，简单的数据处理12345678910111213import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snsimport scikitplot as skpltimport sklearn as skfrom sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import StandardScalerplt.rcParams['font.sans-serif']='fangsong'plt.rcParams['axes.unicode_minus']=Falseimport warningswarnings.filterwarnings(\"ignore\") 123456789101112# 导入原始自杀数据集并重新命名列：originaldata = pd.read_csv('./master.csv')# 国家， 年份， 性别， 年龄， 自杀人数， 人口数量， 自杀人数/总人口*100000（自杀率），# 国家-年份， 人类发展指数（用以衡量联合国各成员国经济社会发展水平的指标，是对传统的GNP指标挑战的结果。）# 年度国内生产总值(衡量经济发展的指标)， 年人均国内生产总值：国内生产总值/人口 ， 世代originaldata.columns = ['country', 'year', 'sex', 'age', 'suicides_no', 'population','suicidesper100k', 'country-year', 'yearlyHDI', 'GDPpyear', 'GDPpcapita', 'generation']originaldata.head() 123456789# 修复和清理原始数据# 将 年度国内生产总值 数据中 ','分割去除掉（比如2,156,624,900），并且转换成float的数字类型originaldata['GDPpyear'] = originaldata.apply(lambda x: float(x['GDPpyear'].replace(',', '')), axis=1)originaldata['GDPpyear'].head(10)# sex 转换为category类型# Categoricals 是 pandas 的一种数据类型，对应着被统计的变量。Categoricals 是由固定的且有限数量的变量组成的。originaldata.sex.astype('category') 1234567891011121314151617181920# 导入额外功能的自杀数据集：extra_data = pd.read_csv('./suicidedataextrafestures.csv')# 国家， 年份， 性别， 年龄， 自杀人数， 人口数量，# 自杀人数/总人口*100000（自杀率）， 国家-年份， 人类发展指数（用以衡量联合国各成员国经济社会发展水平的指标，是对传统的GNP指标挑战的结果。）# 年度国内生产总值(衡量经济发展的指标) ， 年人均国内生产总值：国内生产总值/人口# 世代， 自杀率， 使用互联网的个人(占人口的百分比)， 费用(占国内生产总值的百分比)， 雇员补偿（工资）(占开支的百分比)# 失业总人数(占劳动力总数的百分比)， 医生(每1 000人)， 法律权利指数的强弱(0=弱至12=强)， 劳动力总数# 预期寿命，总计(年)， 移动电话订阅(每100人)# 按原籍国或领土分列的难民人口， 贡献型家庭工人总人数(占总就业人数的百分比)(模拟劳工组织估计数)# 获得电力(占人口的百分比)， 中学毕业率，共计(占相关年龄组的百分比)extra_data.columns = [ 'country', 'year', 'sex', 'age', 'suicides_no', 'population', 'suicidesper100k', 'country-year', 'yearlyHDI', 'GDPpyear', 'GDPpcapita', 'generation', 'suicide%', 'Internetusers', 'Expenses', 'employeecompensation', 'Unemployment', 'Physiciansp1000', 'Legalrights', 'Laborforcetotal', 'Lifeexpectancy', 'Mobilesubscriptionsp100', 'Refugees', 'Selfemployed', 'electricityacess', 'secondarycompletion'] 来自WDI数据库的额外数据中1985年到1994年和2014年的数据空白太多，只能用1995-2013年的数据，因此我决定将数据限制在这段时间内。 123456789df1 = extra_data.copy()# 阿根廷的一系列数据df = df1.iloc[np.where(df1.country == countrynames[0])] for i, x in enumerate(countrynames[1:]): df = df.append(df1.iloc[np.where(df1.country == x)]) #添加剩余的国家数据 df = df[df.year &gt;= 1995] #用 1995-2013年的数据 df = df[df.year &lt;= 2013]df.head(100000000) 2.探索性数据分析1234567891011121314col = plt.cm.Spectral(np.linspace(0, 1, 20))plt.figure(figsize=(8, 6))agedistf = pd.DataFrame(df.groupby('sex').get_group('female').groupby('age').suicides_no.sum())agedistm = pd.DataFrame(df.groupby('sex').get_group('male').groupby('age').suicides_no.sum())plt.bar(agedistm.index, agedistm.suicides_no, color=col[18])plt.bar(agedistf.index, agedistf.suicides_no, color=col[8])plt.legend(['male', 'female'], fontsize=16)plt.ylabel('Count', fontsize=14)plt.xlabel('Suicides per 100K', fontsize=14)plt.show() 总体看下来，不管是哪个年龄段，男性的自杀率都要比女性高。 尤其是25-34岁以及35-54岁年龄段是自杀的高峰期，男女自杀率接近于3：1，而原因是因为工作和生活压力较大，家庭、情感以及经济问题会导致精神崩溃，很容易走上绝路。这是个紧迫而又严肃的问题，不仅要重视身体健康更要重视精神健康。 其次是55-74岁，55岁以上的老年人也已经成为自杀率很高的人群，多是因为孤独而导致抑郁。此外，与子女的矛盾、生理机能丧失也是导致老人抑郁自杀的原因 而15-24岁的青少年也是自杀高危年龄段，这可能是由于青年人学业的压力以及开始走出校园走向工作岗位，并尝试独立生活而又缺乏生活经验，同时又要面临成家立业的巨大压力所导致的。 12345678910111213141516171819col = plt.cm.Spectral(np.linspace(0, 1, 22))plt.figure(figsize=(12, 15))plt.subplot(211)#自杀率（放大1000倍）的平均值最高的前10个国家df.groupby(['country']).suicidesper100k.mean().nlargest(10).plot(kind='bar', color=col) plt.xlabel('Average Suicides/100k', size=20)plt.ylabel('Country', fontsize=20)plt.title('Top 10 countries', fontsize=30)plt.figure(figsize=(12, 15))plt.subplot(212)#自杀人数的平均值最高的前10个国家df.groupby(['country']).suicides_no.mean().nlargest(10).plot(kind='bar', color=col)plt.xlabel('Average Suicides_no', size=20)plt.ylabel('Country', fontsize=20);plt.title('Top 10 countries', fontsize=30)plt.show() 自杀率排在前10的国家为 俄罗斯（欧洲）、 匈牙利（欧洲）、乌克兰（欧洲）、 克罗地亚 （欧洲）、日本（亚洲）、澳大利亚 （大洋洲）、芬兰 （欧洲）、古巴 （美洲）、比利时（欧洲）、 瑞士（欧洲） 自杀人数排前10的国家为 俄罗斯（欧洲）、美国（美洲）、日本（亚洲）、乌克兰（欧洲）、德国（欧洲）、法国（欧洲）、 巴西（美洲）、波兰（欧洲）、泰国 （亚洲）、英国（欧洲）可以发现欧洲国家的自杀人数和自杀率都非常高，例如俄罗斯、乌克兰、英国等。 也可以发现俄罗斯、日本等国家高居自杀率都偏高，这些国家是GDP、就业、奢侈品等方面最强大的国家，并且经济实力也位于世界前列，而导致自杀率高的一个客观原因是人口基数大，主观原因可能是生活节奏飞快，生活代价很高,失业率严重、人际关系紧张等。 12345678910111213141516171819202122232425262728293031plt.figure(figsize=(10, 16))#总人口的各个年龄段的性别分布plt.subplot(311)sns.barplot(x='sex', y='population', hue='age', data=df, palette=\"Greens\") #hue按年龄分组plt.xticks(ha='right', fontsize=20)plt.ylabel('Population', fontsize=20)plt.xlabel('Sex', fontsize=20)plt.title(\"不同年龄段的男、女总人口数\")plt.legend(fontsize=14, loc='best')#自杀人数的各个年龄段的性别分布plt.subplot(312)sns.barplot(x='sex', y='suicides_no', hue='age', data=df, palette=\"Greens\")plt.xticks(ha='right', fontsize=20)plt.ylabel('suicides incidences', fontsize=20)plt.xlabel('Sex', fontsize=20)plt.title(\"不同年龄段的男、女自杀人口数\")plt.legend(fontsize=14)#自杀率（放大1000倍）的各个年龄段的性别分布plt.subplot(313)sns.barplot(x='sex', y='suicidesper100k', hue='age', data=df,palette=\"Greens\")plt.xticks(ha='right', fontsize=20);plt.ylabel('suicidesper100k',fontsize=20);plt.xlabel('Sex',fontsize=20);plt.title(\"不同年龄段的男、女自杀率\")plt.legend(fontsize=14);plt.subplots_adjust(top=1.2)plt.show() 图1为 各个不同年龄段的男、女总人口数据柱状图。 就总人口而言 各个年龄段的男女比例差不多。图2为 各个不同年龄段的男、女自杀人口数据柱状图。 可以很明显的看出男性的自杀人数远远大于女性自杀人数。 其可能的原因男性所承受的压力要多于女性，精神方面会变得脆弱，并会导致身体不健康以及精神不健康。图3为 各个不同年龄段的男、女自杀率人口数据柱状图。 就75+，也就是老年阶段，从侧面也反映出老龄化的问题。 在老龄化进程加速的状况下，社会保障体系和社会经济文化的发展难以满足老年人的物质和精神需求， 多重矛盾造就了本该安享晚年的老年人，出现了比年轻人更严重的生存和精神压力。 所以，老年人的生存现状需要受到重视，应该不断出台老年人的保障措施，来保障老年人的老年生活。 1234567891011plt.figure(figsize=(12, 16))# 具体按性别和年份 来看 男女的自杀率plt.subplot(311)sns.lineplot(x='year', y='suicidesper100k', hue='sex', data=df, palette=\"hot\") #hue按年龄分组plt.xticks(ha='right', fontsize=20)plt.ylabel('suicidesper100k', fontsize=20)plt.xlabel('year', fontsize=20)plt.legend(fontsize=14, loc='best') plt.title(\"性别年份与自杀率关系图\")plt.show() 图为 具体按性别和年份 来看 男女的自杀率 1995年-2013年男性自杀率远远大于女性。 女性自杀率水平在0.005%左右，男性自杀率水平在0.02%左右，男性自杀率约是女性的4倍。从时间来看，在这区间，全球范围综合自杀率并没有出现明显的下降结合分析，在全球范围内，男性自杀率高于女性，约为女性自杀率的4倍左右。在现代社会中男性承担的社会责任相对较大，相应的压力也会增加。所以一个国家应该关注于提升人民生活质量，健全保障体系。在每个家庭面对突发的困难是能够提供一定的保障，例如失业，生病，意外事故等。全球范围内，年龄越大的人群自杀率相对较高。在现在全球人口老龄化的趋势下，这种情况无疑更加严峻。关于老年人群的生活的物质条件需要改善，其心理更需要梳理与关注。 12345678910111213plt.figure(figsize=(8, 6))#选出year列并且去除重复的年份year = originaldata.groupby('year').year.unique()#各个年份的自杀人数汇总#使用seaborn进行可视化,输入的数据必须为dataframetotalpyear = pd.DataFrame(originaldata.groupby('year').suicides_no.sum()) plt.plot(year.index[0:31], totalpyear[0:31], color=col[18]) #选取范围为[0:31] 1985年到2015年plt.xlabel('year', fontsize=15)plt.ylabel('Total number of suicides in the world', fontsize=15)plt.show() 世界自杀人数趋势2000年之前逐步上升，2000年后呈现缓慢下降趋势 在2000年之前，人们所处的地区条件乏善可陈，人群受教育程度偏低，社会动荡，经济发展水平不高。 之后，随着科技的进步以及社会经济不断发展，社会更加安稳。混乱、贫穷、饥饿的现象变少，人们的的焦虑有改善。各国政府在医疗保健上的投入和家庭护理的提升也会使自杀趋势降低。 123456789101112131415161718plt.figure(figsize=(20, 8))# 自杀率（放大1000倍）的分布情况，y轴为个数plt.subplot(121)plt.hist(df.suicidesper100k, bins=30, color=col[18]) #bins:条形数plt.xlabel('Suicides per 100K of population', fontsize=25)plt.xticks(rotation = 0, fontsize = 20) plt.ylabel('count', fontsize=25)plt.yticks( fontsize = 20) # 年人均国内生产总值的分布情况，y轴为个数plt.subplot(122)plt.hist(df.GDPpcapita, bins=30, color=col[7])plt.xlabel('GDP', fontsize=25)plt.xticks(rotation = 0,fontsize = 20) plt.ylabel('count', fontsize=25)plt.yticks(fontsize = 20) plt.show() 1234567891011121314151617181920212223242526272829303132plt.figure(figsize=(8, 5))# suicides：“GDP年度国内生产总值（美元）”，“雇员补偿%”，“失业人数%”，“预期寿命” 按“年份”分组suicides = df[['year', 'GDPpyear', 'Selfemployed', 'Unemployment', 'Lifeexpectancy']].groupby('year').mean()# suicides['Suicides'] 为各年份的自杀率总数suicides['Suicides'] = df[['country', 'year', 'suicidesper100k']].groupby('year').sum()# suicides.index ：从1995到2013年， # GDPpyear/suicides.GDPpyear.max() ： GDP年度国内生产总值/最大GDP年度国内生产总值plt.plot(suicides.index, suicides.GDPpyear/suicides.GDPpyear.max(), color=col[1]) # suicides.Unemployment：失业总人数(占劳动力总数的百分比)(模拟劳工组织估计数)# suicides.Unemployment.max()：最大值plt.plot(suicides.index, suicides.Unemployment/suicides.Unemployment.max(), color=col[7])# suicides.Lifeexpectancy ； 各年的预期寿命plt.plot(suicides.index, suicides.Lifeexpectancy/suicides.Lifeexpectancy.max(), color=col[14])# suicides.Suicides ：各年的自杀率plt.plot(suicides.index, suicides.Suicides/suicides.Suicides.max(), color=col[17])plt.legend( ['global average GDPpyear', #红线 'global average Unemployment', #黄线 'global average Life expectancy', #绿线 'Total suicides per 100k'], fontsize=14, loc='best' #蓝线 )plt.ylabel('Normalized', fontsize=14)plt.xlabel('year', fontsize=14)plt.title(\"各年份全球平均GDP、平均失业率、平均预期寿命、平均自杀率趋势图\")plt.show() 从图中可以看出自1995 - 2013年， 全球的GDP不断上涨，1995年到2000年缓慢上涨，2000年以后经济增长的势头更强；受到金融危机的影响，2008年经济下滑后又开始增长。 全球的失业率也随经济，社会发展，1995-2008逐年降低，之后又攀升。 全球的人预期寿命也随着经济的不断发展逐年上升，人民生活水平提高。 全球的整体自杀率是呈下降趋势的，背后的原因可能是社会的安稳，国家政府的干预，各国政府在医疗保健上的投入和家庭护理的提升。 12345678910111213141516171819202122232425corr = total.corr() #相关系数矩阵，即给出了任意两个变量之间的相关系数# 相关矩阵的上三角部分与下三角对称。因此，热图不需要显示整个矩阵。在下一步隐藏上三角形。# 设置mask隐藏上三角# np.zeros_like() 返回一个零数组，其形状和类型与给定的数组相同。# 该 dtype=np.bool 参数会覆盖数据类型，因此我们的数组是一个布尔数组。# np.triu_indices_from(mask) 返回数组上三角形的索引。# 现在，我们将上三角形设置为True。 mask[np.triu_indices_from(mask)]= Truemask = np.zeros_like(corr, dtype=np.bool)mask[np.triu_indices_from(mask)] = True# 在Seaborn中创建热图f, ax = plt.subplots(figsize=(10, 8))# 生成自定义发散颜色图cmap = sns.diverging_palette(220, 10, as_cmap=True)# 绘制热图# 数据为 corr# vmax,vmin:分别是热力图的颜色取值最大和最小范围# center:数据表取值有差异时，设置热力图的色彩中心对齐值；通过设置center值，可以调整生成的图像颜色的整体深浅# square:设置热力图矩阵小块形状，默认值是False# linewidths(矩阵小块的间隔),# cbar_kws:热力图侧边绘制颜色刻度条时，相关字体设置，默认值是Nonesns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, vmin=-1, center=0, square=True, linewidths=0.2, cbar_kws=&#123;\"shrink\": 0.8&#125;) 3.数据预处理1234567891011# 对使用互联网的个人(占人口的百分比) 用最小值填充 在原数据直接修改total.Internetusers.fillna(total.Internetusers. min(), inplace=True)# 对难民人口用8填充total.Refugees.fillna(total.Refugees. min(), inplace=True)#对雇员补偿(占开支的百分比)用均值填充total.employeecompensation.fillna(total.employeecompensation.mean(), inplace=True)# 对总人口用均值填充total.population.fillna(total.population.mean(), inplace=True) 自杀风险的二元分类 对自杀数据进行二元分类，根据 自杀率（扩大1000倍） 作为高/低自杀风险来划分风险等级。在“total”data frame中添加一个额外的列作为‘risk’。 Suicides &lt; mean(Suicides) –&gt; 低风险 –&gt; class 0 Suicides &gt; mean(Suicides) –&gt; 高风险 –&gt; class 1 123# 小于平均值的为低风险，大于平均值的为高风险total['risk'] = total.Suicides.copy()total['risk'] = np.where(total.risk &lt; total.Suicides.mean(), 0, 1) 1234567891011121314plt.figure(figsize=(16, 5))plt.subplot(121)plt.hist(total.risk, color=col[8])plt.ylabel('counts', fontsize=20)plt.xlabel('Suicide risk', fontsize=20)plt.title(\"自杀高低风险数量\")plt.subplot(122)sns.distplot(total.Suicides[total.risk == 0], bins=10)sns.distplot(total.Suicides[total.risk == 1], bins=20) plt.xlabel('Suicides', fontsize=20)plt.title(\"自杀高低风险分布情况\")plt.show() 12345678910111213141516171819202122# 对国家进行 标准化标签，将标签值统一转换成range(标签值个数-1)范围内# 相当于fit(X).transform(X),意思就是先进行fit(),进行数据拟合，然后在进行transform() 进行标准化处理from sklearn.preprocessing import LabelEncoderle = LabelEncoder()total.country = le.fit_transform(total.country) total.country.unique()# 为建立模型准备数据# totalfeatures 数据的 11个特征# array和asarray都可以将结构数据转化为ndarray # ndarray是Numpy中的数据结构，是一个多维数组，可以理解为矩阵，具有矢量运算能力，快速、节省空间X = np.asarray(total[totalfeatures])y = np.asarray(total['risk'])# 对数据应用标准定标器，因为ML算法的工作假设是数据是正态分布的# 标准化数据# sklearn.preprocessing.StandardScaler() 可保存训练集中的均值、方差参数，然后直接用于转换测试集数据。scaler = StandardScaler()scaler.fit(X)X_scaled = scaler.transform(X) 划分训练集、测试集和验证集 1234567# 将数据集拆分为训练集和测试集 576行 11个特征# 首先将该数据3/4作为训练集，1/4作为测试集；再由训练集划分1/5作为验证集X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=4)X_train,X_valid,y_train,y_valid=train_test_split(X_train,y_train,test_size=0.2,random_state=4)print('Train set:', X_train.shape, y_train.shape)print('Test set:', X_test.shape, y_test.shape)print('Test set:', X_valid.shape, y_valid.shape) 123456789101112131415161718192021222324252627282930313233# GDP = 雇员报酬 + 固定资产消耗 + 生产税和进口税净额 + 营业盈余# 这里面的“雇员报酬”仅仅只是GDP其中的一个组成部分ax1 = total[total['risk'] == 1][0:200].plot(kind='scatter', x='GDPpcapita', y='employeecompensation', color='DarkRed', label='high risk', figsize=(6, 5), fontsize=12)total[total['risk'] == 0][0:200].plot(kind='scatter', x='GDPpcapita', y='employeecompensation', color='DarkBlue', label='low risk', ax=ax1)plt.ylabel('employeecompensation', fontsize=16)plt.xlabel('GDP per capita', fontsize=16)plt.legend(fontsize=14)# 预期寿命 和 贡献型家庭工人总人数(占总就业人数的百分比) 的高低风险ax1 = total[total['risk'] == 1][0:200].plot(kind='scatter', x='Lifeexpectancy', y='Selfemployed', color='DarkRed', label='high risk', figsize=(6, 5), fontsize=12)total[total['risk'] == 0][0:200].plot(kind='scatter', x='Lifeexpectancy', y='Selfemployed', color='DarkBlue', label='low risk', ax=ax1);plt.ylabel('Selfemployed', fontsize=16)plt.xlabel('Lifeexpectancy', fontsize=16)plt.legend(fontsize=14)# 人均国内生产总值(美元) 和 失业总人数(占劳动力总数的百分比) 的高低风险ax1 = total[total['risk'] == 1][0:200].plot(kind='scatter', x='GDPpcapita', y='Unemployment', color='DarkRed', label='high risk', figsize=(6, 5), fontsize=12);total[total['risk'] == 0][0:200].plot(kind='scatter', x='GDPpcapita', y='Unemployment', color='DarkBlue', label='low risk', ax=ax1);plt.ylabel('Unemployment', fontsize=16)plt.xlabel('GDP per capita', fontsize=16)plt.legend(fontsize=14)plt.show() 图1为 人均GDP 和 雇员的报酬（工资）(占开支的百分比) 的关于自杀率高低的一个分类。 雇员的报酬（工资） 是 人均GDP 的一部分，人均gdp集中在5000-50000美元；而工资占开销的 10%-30%，在人均gdp大致相同的情况下，工资越高，那么自杀率相对会低，但是即使人均gdp很高的情况下，工资如果很低，自杀率也会偏高。 图2为 预期寿命 和 供养家庭职工总人数(占总就业人数的百分比) 的高低风险 预期寿命分布在70-82岁，而在预期寿命相同的情况下，若供养家庭职工总人数多，则自杀风险相对会低 图3为 人均国内生产总值(美元) 和 失业总人数(占劳动力总数的百分比) 的高低风险 人均gdp越高，自杀率还是较低的；在人均gdp较低（0-15000美元）下，失业的人数反而不算高；但在中产和富裕阶级中，失业人数越高，自杀风险更大。 123456789# 关于年份的高低自杀风险fig = plt.figure(figsize=(30, 30))plt.subplot(4, 3, 1)sns.distplot(total[total.columns[0]][total.risk == 0], label='low risk')sns.distplot(total[total.columns[0]][total.risk == 1], label='high risk') plt.legend(loc='best', fontsize=18) plt.xlabel(total.columns[0], fontsize=18)plt.show() 4.建模根据他的要求，使用逻辑回归、决策树、随机森林这三种模型，并且对比找到最好的分类模型。 12345678910111213141516171819202122from sklearn.linear_model import LogisticRegressionfrom sklearn.metrics import recall_score,accuracy_scorefrom sklearn.metrics import precision_recall_fscore_supportfrom sklearn.metrics import confusion_matrix, classification_reportLR = LogisticRegression(C=0.001, solver='liblinear').fit(X_train, y_train)# 预测类别:0还是1yLRhat = LR.predict(X_valid) # 预测 0或1的概率（例如 [0.54689436, 0.45310564] 预测出来为0）yLRhat_prob = LR.predict_proba(X_valid)cm = confusion_matrix(y_valid, yLRhat)print('\\n confusion matrix：混淆矩阵 \\n', cm)print('此时模型准确率为:',accuracy_score(y_valid, yLRhat))print('********************************************************')print('\\n')print('逻辑回归模型的分类报告\\n', classification_report(y_valid, yLRhat))skplt.metrics.plot_confusion_matrix(y_valid,yLRhat,normalize=True)plt.show() 这里的超参数调整我使用网格搜索，因为逻辑回归的超参数较少且模型训练的比较快,而且网格搜索自带就有交叉验证。 123456789101112131415161718192021from sklearn.model_selection import GridSearchCVparam=&#123;\"tol\":[1e-4, 1e-3,1e-2], \"C\":[0.4, 0.6, 0.8]&#125;grid = GridSearchCV(LogisticRegression(),param_grid=param, cv=5)#这里是5折交叉验证grid.fit(X_train,y_train)print(grid.best_params_)print(grid.best_score_)#得到最好的逻辑回归分类器best_LR=grid.best_estimator_ #进行训练、预测best_LR.fit(X_train,y_train)pred=best_LR.predict(X_valid)cm = confusion_matrix(y_valid, pred)print('\\n confusion matrix：混淆矩阵 \\n', cm)print('最好的逻辑回归模型准确率为:',accuracy_score(y_valid, pred))print('********************************************************')print('\\n')print('最好的逻辑回归模型的分类报告\\n', classification_report(y_valid, pred)) 逻辑回归分类效果并不好，再来看看决策树 1234567891011121314151617181920212223242526272829303132from sklearn.tree import DecisionTreeClassifierfrom sklearn.metrics import accuracy_scorefrom sklearn.metrics import confusion_matrix, classification_report# 决策树学习# 函数为创建一个决策树模型# criterion：gini或者entropy,前者是基尼系数，后者是信息熵。# max_depth： int or None, optional (default=None) 设置决策随机森林中的决策树的最大深度，深度越大，越容易过拟合，推荐树的深度为：5-20之间。# max_leaf_nodes： 通过限制最大叶子节点数，可以防止过拟合，默认是\"None”，即不限制最大的叶子节点数。DT = DecisionTreeClassifier(criterion=\"entropy\", max_depth=7, max_leaf_nodes=30)DT.fit(X_train, y_train)ydthat = DT.predict(X_valid)print('***决策树模型***')#决策树模型性能评估print('验证集上的准确率:', DT.score(X_valid, y_valid))print('训练集上的准确率:', DT.score(X_train, y_train))# 混淆矩阵print('CM\\n', confusion_matrix(y_valid, ydthat))print('********************************************************')print('决策树模型的分类报告\\n', classification_report(y_valid, ydthat))DTfeat_importance = DT.feature_importances_DTfeat_importance = pd.DataFrame([totalfeatures, DT.feature_importances_]).T# 特征重要性排序print(\"特征重要性排名如下:\")print(f'\\n一共有&#123;DT.n_features_&#125;个特征')print(DTfeat_importance.sort_values(by=1, ascending=False)) 123456789101112131415161718192021222324252627282930313233# 通过cv_results观察过程并做图max_depth=np.arange(0,20,3)max_leaf_nodes=np.arange(0,30,3)min_samples_leaf =np.arange(0,20,2)param1= &#123;'criterion':['entropy'],'max_depth':max_depth&#125;param2= &#123;'criterion':['entropy'],'min_samples_leaf':min_samples_leaf&#125;param3= &#123;'criterion':['entropy'],'max_leaf_nodes':max_leaf_nodes&#125;clf1 = GridSearchCV(DecisionTreeClassifier(),param_grid=param1,cv=6)clf1.fit(X_train,y_train)clf2 = GridSearchCV(DecisionTreeClassifier(),param_grid=param2,cv=6)clf2.fit(X_train,y_train)clf3 = GridSearchCV(DecisionTreeClassifier(),param_grid=param3,cv=6)clf3.fit(X_train,y_train)fig = plt.figure()ax = fig.add_subplot(311)ax.plot(min_samples_leaf,clf2.cv_results_['mean_test_score'],'g*-')plt.title('决策树模型网格搜索的训练过程')ax = fig.add_subplot(312)ax.plot(max_depth,clf1.cv_results_['mean_test_score'],'g*-')ax = fig.add_subplot(313)ax.plot(max_leaf_nodes,clf3.cv_results_['mean_test_score'],'g*-')plt.show() 1234567891011121314151617181920212223best_DT = DecisionTreeClassifier(criterion=\"entropy\", max_depth=15, max_leaf_nodes=25,min_samples_leaf=4)best_DT.fit(X_train, y_train)ydthat =best_DT.predict(X_valid)print('***决策树模型***')#决策树模型性能评估print('验证集上的准确率:',best_DT.score(X_valid, y_valid))print('训练集上的准确率:',best_DT.score(X_train, y_train))# 混淆矩阵print('CM\\n', confusion_matrix(y_valid, ydthat))print('********************************************************')print('决策树模型的分类报告\\n', classification_report(y_valid, ydthat))DTfeat_importance = best_DT.feature_importances_DTfeat_importance = pd.DataFrame([totalfeatures, DT.feature_importances_]).T# 特征重要性排序print(\"特征重要性排名如下:\")print(f'\\n一共有&#123;best_DT.n_features_&#125;个特征')print(DTfeat_importance.sort_values(by=1, ascending=False)) 1234567891011121314151617181920# 随机森林可以视为多颗决策树的集成，鲁棒性更强，泛化能力更好，不易产生过拟合现象。但是噪声比较大的情况下会过拟合。from sklearn.ensemble import RandomForestClassifierrandom_forest = RandomForestClassifier(n_estimators=20, max_depth=10, min_samples_split=2, min_samples_leaf=5, max_leaf_nodes=20, max_features=len(totalfeatures)) random_forest.fit(X_train, y_train)yrfhat = random_forest.predict(X_valid)feat_importance = random_forest.feature_importances_rffeat_importance = pd.DataFrame([totalfeatures, random_forest.feature_importances_]).Tprint('******************Random forest classifier**************')print('训练集上的准确率', random_forest.score(X_train, y_train))print('验证集上的准确率', random_forest.score(X_valid,y_valid))print('混淆矩阵\\n', confusion_matrix(y_valid, yrfhat))print('********************************************************')print('随机森林的分类报告\\n', classification_report(y_valid, yrfhat))print(rffeat_importance.sort_values(by=1, ascending=False)) 1234567891011121314151617181920212223242526272829#我们首先对n_estimators进行网格搜索：param_test1 = &#123;'n_estimators':[50,120,160,200,250]&#125;gsearch1 = GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_test1,cv=5)gsearch1.fit(X_train,y_train)print( gsearch1.best_params_, gsearch1.best_score_)#接着我们对决策树最大深度max_depth和内部节点再划分所需最小样本数min_samples_split进行网格搜索。param_test2 = &#123;'max_depth':[1,2,3,5,7,9,11,13,20],'min_samples_split':[5,10,25,50,100,120,150]&#125;gsearch2 = GridSearchCV(estimator = RandomForestClassifier(n_estimators=200),param_grid = param_test2, cv=5)gsearch2.fit(X_train,y_train)print( gsearch2.best_params_, gsearch2.best_score_)#最好的随机森林模型best_rf=RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=10) best_rf .fit(X_train, y_train)yrfhat = best_rf .predict(X_valid)feat_importance = best_rf.feature_importances_rffeat_importance = pd.DataFrame([totalfeatures, random_forest.feature_importances_]).Tprint('******************随机森林模型**************')print('训练集上的准确率',best_rf.score(X_train, y_train))print('验证集上的准确率',best_rf.score(X_valid,y_valid))print('混淆矩阵\\n', confusion_matrix(y_valid, yrfhat))print('********************************************************')print('最好的随机森林模型的分类报告\\n', classification_report(y_valid, yrfhat))print(rffeat_importance.sort_values(by=1, ascending=False)) 通过roc比较三种模型性能 12345678910models = [best_LR, best_DT,best_rf]modelnames = ['Logistic regression', 'Random Forest', 'Decison tree']for i, x in enumerate(models): y_true = y_test y_probas = x.predict_proba(X_test) ax1 = skplt.metrics.plot_roc(y_true, y_probas, plot_micro=False, plot_macro=True, classes_to_plot=[], figsize=(5, 5)) plt.axis((-0.01, 1, 0, 1.1)) plt.legend([modelnames[i]], loc='best') 12345678910111213dtpred=best_DT.predict(X_test)rfpred=best_rf.predict(X_test)dt_score=accuracy_score(y_test,dtpred)rf_score=accuracy_score(y_test,rfpred)print(\"决策树在测试集上准确率为:\",dt_score)print(\"随机森林在测试集上准确率为:\",rf_score)if dt_score&gt;rf_score: print(\"决策树模型是三者中最好的分类模型\")else: print(\"随机森林是三者中最好的分类模型\") 5.分析与总结 分析：从上面的条形图中我们可以发现影响自杀率的主要特征是employeecompensation、Selfemployed、Refugees、country、GDPpyear、population 首先我们的自杀率=自杀人数/总人口数接下来我们就对这几个特征影响自杀率的原因进行分析： employeecompensation（工资）当工资低，占开支的百分比较少时，也就意味着生活质量很低，从而自杀率升高； Selfemployed（个体经营家庭总人数占比）当个体经营家庭总人数占比高时，就业压力相对较小，所以自杀率较低； Refugees（难民人口）当难民人口较多时，难民生存困难，很有可能就因为各种原因堕落消沉从而导致自杀率升高； country（国家）发达国家的人民生活节奏快，竞争压力大，失业率高，所以自杀率高； GDPpyear（国家的年度生产总值）经济发展快速的国家，也就有更大的就业竞争压力，从而GDPpyear高的国家自杀率高； population（人口数量）由于我们计算的是自杀率，从而人口数量也是一个影响因素；当具有相同自杀人数时，人口总数越高，自杀率越低；而人口基数越大，自杀率也会升高。 总结：对于一个国家来说 当人们工资少，那么自杀率会升高（最重要！！！也说明了物质社会人们对于物质的需求还是很渴望的） 当每个家庭和睦、家庭氛围好，家庭压力小，那么自杀率会降低 当难民较多，那么自杀率会升高 当国家越发达，GDP越高，那么生活节奏飞快，生活成本很高,失业率严重、人际关系紧张等，从而导致自杀率高 对于人口数量多的国家，自杀人数处于正态分布，当人口数量足够大时，相应的自杀率也就很小 全球范围内，年龄越大的人群自杀率相对较高。在现在全球人口老龄化的趋势下，这种情况无疑更加严峻。关于老年人群的生活的物质条件需要改善，其心理更需要梳理与关注。而男性比起女性来说社会压力更大，从而自杀率也更大，所以公司也应该定期对职员进行心理疏导。 6.不足与改进：不足： 从这次数据分析基本得到了结论，也与实际相符合，但是回顾来看，模型依然是过拟合的，我们只能减小过拟合程度；对于网格搜索的超参数由于各种原因限制，我们也无法实验所有的超参数，从而也无法真正得到最优参数与最优模型，得到的只能是相对较好的，泛化能力较强的模型；但是随机森林作为最好的分类模型，虽然它的受噪音影响小，鲁棒性更强，但是如果数据噪音较大也容易过拟合。 改进： 我们可以尝试更多的分类模型，比如：SVM、KNN、MLP或者是更复杂的神经网络 我们可以先对数据特征做处理，比如特征提取（PCA、LDA、SVD），特征提取（Filter、Wrapper、Embedded），或者基于不纯度的减少量作为指标，得到最主要的特征再进行建模 加入更多的超参数进行搜索，得到更贴近最好的分类模型 最后这个世界有意思的事情还是很多的，稍微别那么在乎物质需求方面，会发现世界的另一面。总之还是积极向上点吧，我继续极限导数微分积分去了。","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p><img src=\"https://img-blog.csdnimg.cn/20200304072207629.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>究竟是什么让我凌晨四点一边看着人家吃美食，一边敲代码，写博客，原因呢就是需要帮别人做这次的数据分析。<br><img src=\"https://img-blog.csdnimg.cn/20200304073747402.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h1 id=\"数据分析的背景\"><a href=\"#数据分析的背景\" class=\"headerlink\" title=\"数据分析的背景\"></a>数据分析的背景</h1><p>来自于kaggle的一次比赛<br><a href=\"https://www.kaggle.com/russellyates88/suicide-rates-overview-1985-to-2016\" target=\"_blank\" rel=\"noopener\">点这里去查看/下载数据</a><br><img src=\"https://img-blog.csdnimg.cn/2020030407315120.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/20200304073221584.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>关于数据集的介绍等下在代码中可以看到，这里就不多说了。<br>这次竞赛就是通过一系列特征来找到自杀率上升的信号（也就是影响自杀率的因素）</p>\n<a id=\"more\"></a>\n\n<h1 id=\"开始数据分析\"><a href=\"#开始数据分析\" class=\"headerlink\" title=\"开始数据分析\"></a>开始数据分析</h1><h2 id=\"1-导库、导数据，简单的数据处理\"><a href=\"#1-导库、导数据，简单的数据处理\" class=\"headerlink\" title=\"1.导库、导数据，简单的数据处理\"></a>1.导库、导数据，简单的数据处理</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"><span class=\"keyword\">import</span> scikitplot <span class=\"keyword\">as</span> skplt</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn <span class=\"keyword\">as</span> sk</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> StandardScaler</span><br><span class=\"line\">plt.rcParams[<span class=\"string\">'font.sans-serif'</span>]=<span class=\"string\">'fangsong'</span></span><br><span class=\"line\">plt.rcParams[<span class=\"string\">'axes.unicode_minus'</span>]=<span class=\"literal\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> warnings</span><br><span class=\"line\">warnings.filterwarnings(<span class=\"string\">\"ignore\"</span>)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入原始自杀数据集并重新命名列：</span></span><br><span class=\"line\"></span><br><span class=\"line\">originaldata = pd.read_csv(<span class=\"string\">'./master.csv'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 国家，  年份，  性别，  年龄，  自杀人数，  人口数量，  自杀人数/总人口*100000（自杀率），</span></span><br><span class=\"line\"><span class=\"comment\"># 国家-年份，     人类发展指数（用以衡量联合国各成员国经济社会发展水平的指标，是对传统的GNP指标挑战的结果。）</span></span><br><span class=\"line\"><span class=\"comment\"># 年度国内生产总值(衡量经济发展的指标)，      年人均国内生产总值：国内生产总值/人口 ，         世代</span></span><br><span class=\"line\">originaldata.columns = [<span class=\"string\">'country'</span>, <span class=\"string\">'year'</span>, <span class=\"string\">'sex'</span>, <span class=\"string\">'age'</span>, <span class=\"string\">'suicides_no'</span>, <span class=\"string\">'population'</span>,<span class=\"string\">'suicidesper100k'</span>,</span><br><span class=\"line\">                      <span class=\"string\">'country-year'</span>, <span class=\"string\">'yearlyHDI'</span>, </span><br><span class=\"line\">                        <span class=\"string\">'GDPpyear'</span>, <span class=\"string\">'GDPpcapita'</span>, <span class=\"string\">'generation'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">originaldata.head()</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304073904522.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 修复和清理原始数据</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将 年度国内生产总值 数据中 ','分割去除掉（比如2,156,624,900），并且转换成float的数字类型</span></span><br><span class=\"line\">originaldata[<span class=\"string\">'GDPpyear'</span>] = originaldata.apply(<span class=\"keyword\">lambda</span> x: float(x[<span class=\"string\">'GDPpyear'</span>].replace(<span class=\"string\">','</span>, <span class=\"string\">''</span>)), axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">originaldata[<span class=\"string\">'GDPpyear'</span>].head(<span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># sex 转换为category类型</span></span><br><span class=\"line\"><span class=\"comment\"># Categoricals 是 pandas 的一种数据类型，对应着被统计的变量。Categoricals 是由固定的且有限数量的变量组成的。</span></span><br><span class=\"line\">originaldata.sex.astype(<span class=\"string\">'category'</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304073958581.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入额外功能的自杀数据集：</span></span><br><span class=\"line\">extra_data = pd.read_csv(<span class=\"string\">'./suicidedataextrafestures.csv'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 国家，   年份，   性别，   年龄，    自杀人数，    人口数量，</span></span><br><span class=\"line\"><span class=\"comment\"># 自杀人数/总人口*100000（自杀率），   国家-年份，   人类发展指数（用以衡量联合国各成员国经济社会发展水平的指标，是对传统的GNP指标挑战的结果。）</span></span><br><span class=\"line\"><span class=\"comment\"># 年度国内生产总值(衡量经济发展的指标) ，    年人均国内生产总值：国内生产总值/人口</span></span><br><span class=\"line\"><span class=\"comment\"># 世代， 自杀率，  使用互联网的个人(占人口的百分比)，     费用(占国内生产总值的百分比)，    雇员补偿（工资）(占开支的百分比)</span></span><br><span class=\"line\"><span class=\"comment\"># 失业总人数(占劳动力总数的百分比)，   医生(每1 000人)，    法律权利指数的强弱(0=弱至12=强)，   劳动力总数</span></span><br><span class=\"line\"><span class=\"comment\"># 预期寿命，总计(年)，        移动电话订阅(每100人)</span></span><br><span class=\"line\"><span class=\"comment\"># 按原籍国或领土分列的难民人口，    贡献型家庭工人总人数(占总就业人数的百分比)(模拟劳工组织估计数)</span></span><br><span class=\"line\"><span class=\"comment\"># 获得电力(占人口的百分比)，        中学毕业率，共计(占相关年龄组的百分比)</span></span><br><span class=\"line\">extra_data.columns = [</span><br><span class=\"line\">    <span class=\"string\">'country'</span>, <span class=\"string\">'year'</span>, <span class=\"string\">'sex'</span>, <span class=\"string\">'age'</span>, <span class=\"string\">'suicides_no'</span>, <span class=\"string\">'population'</span>,</span><br><span class=\"line\">    <span class=\"string\">'suicidesper100k'</span>, <span class=\"string\">'country-year'</span>, <span class=\"string\">'yearlyHDI'</span>,</span><br><span class=\"line\">    <span class=\"string\">'GDPpyear'</span>, <span class=\"string\">'GDPpcapita'</span>, </span><br><span class=\"line\">    <span class=\"string\">'generation'</span>, <span class=\"string\">'suicide%'</span>, <span class=\"string\">'Internetusers'</span>, <span class=\"string\">'Expenses'</span>, <span class=\"string\">'employeecompensation'</span>,</span><br><span class=\"line\">    <span class=\"string\">'Unemployment'</span>, <span class=\"string\">'Physiciansp1000'</span>, <span class=\"string\">'Legalrights'</span>, <span class=\"string\">'Laborforcetotal'</span>,</span><br><span class=\"line\">    <span class=\"string\">'Lifeexpectancy'</span>, <span class=\"string\">'Mobilesubscriptionsp100'</span>,</span><br><span class=\"line\">    <span class=\"string\">'Refugees'</span>, <span class=\"string\">'Selfemployed'</span>, </span><br><span class=\"line\">    <span class=\"string\">'electricityacess'</span>, <span class=\"string\">'secondarycompletion'</span>]</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304074022587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>来自WDI数据库的额外数据中1985年到1994年和2014年的数据空白太多，只能用1995-2013年的数据，因此我决定将数据限制在这段时间内。</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df1 = extra_data.copy()</span><br><span class=\"line\"><span class=\"comment\"># 阿根廷的一系列数据</span></span><br><span class=\"line\">df = df1.iloc[np.where(df1.country == countrynames[<span class=\"number\">0</span>])] </span><br><span class=\"line\"><span class=\"keyword\">for</span> i, x <span class=\"keyword\">in</span> enumerate(countrynames[<span class=\"number\">1</span>:]):</span><br><span class=\"line\">    df = df.append(df1.iloc[np.where(df1.country == x)])  <span class=\"comment\">#添加剩余的国家数据</span></span><br><span class=\"line\">    </span><br><span class=\"line\">df = df[df.year &gt;= <span class=\"number\">1995</span>] <span class=\"comment\">#用 1995-2013年的数据  </span></span><br><span class=\"line\">df = df[df.year &lt;= <span class=\"number\">2013</span>]</span><br><span class=\"line\">df.head(<span class=\"number\">100000000</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-探索性数据分析\"><a href=\"#2-探索性数据分析\" class=\"headerlink\" title=\"2.探索性数据分析\"></a>2.探索性数据分析</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">col = plt.cm.Spectral(np.linspace(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">20</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">agedistf = pd.DataFrame(df.groupby(<span class=\"string\">'sex'</span>).get_group(<span class=\"string\">'female'</span>).groupby(<span class=\"string\">'age'</span>).suicides_no.sum())</span><br><span class=\"line\"></span><br><span class=\"line\">agedistm = pd.DataFrame(df.groupby(<span class=\"string\">'sex'</span>).get_group(<span class=\"string\">'male'</span>).groupby(<span class=\"string\">'age'</span>).suicides_no.sum())</span><br><span class=\"line\"></span><br><span class=\"line\">plt.bar(agedistm.index, agedistm.suicides_no, color=col[<span class=\"number\">18</span>])</span><br><span class=\"line\">plt.bar(agedistf.index, agedistf.suicides_no, color=col[<span class=\"number\">8</span>])</span><br><span class=\"line\">plt.legend([<span class=\"string\">'male'</span>, <span class=\"string\">'female'</span>], fontsize=<span class=\"number\">16</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Count'</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Suicides per 100K'</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/2020030407424436.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><strong>总体看下来，不管是哪个年龄段，男性的自杀率都要比女性高。 尤其是25-34岁以及35-54岁年龄段是自杀的高峰期，男女自杀率接近于3：1，而原因是因为工作和生活压力较大，家庭、情感以及经济问题会导致精神崩溃，很容易走上绝路。这是个紧迫而又严肃的问题，不仅要重视身体健康更要重视精神健康。 其次是55-74岁，55岁以上的老年人也已经成为自杀率很高的人群，多是因为孤独而导致抑郁。此外，与子女的矛盾、生理机能丧失也是导致老人抑郁自杀的原因 而15-24岁的青少年也是自杀高危年龄段，这可能是由于青年人学业的压力以及开始走出校园走向工作岗位，并尝试独立生活而又缺乏生活经验，同时又要面临成家立业的巨大压力所导致的。</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">col = plt.cm.Spectral(np.linspace(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">22</span>))</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">15</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">211</span>)</span><br><span class=\"line\"><span class=\"comment\">#自杀率（放大1000倍）的平均值最高的前10个国家</span></span><br><span class=\"line\">df.groupby([<span class=\"string\">'country'</span>]).suicidesper100k.mean().nlargest(<span class=\"number\">10</span>).plot(kind=<span class=\"string\">'bar'</span>, color=col) </span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Average Suicides/100k'</span>, size=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Country'</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Top 10 countries'</span>, fontsize=<span class=\"number\">30</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">15</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">212</span>)</span><br><span class=\"line\"><span class=\"comment\">#自杀人数的平均值最高的前10个国家</span></span><br><span class=\"line\">df.groupby([<span class=\"string\">'country'</span>]).suicides_no.mean().nlargest(<span class=\"number\">10</span>).plot(kind=<span class=\"string\">'bar'</span>, color=col)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Average Suicides_no'</span>, size=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Country'</span>, fontsize=<span class=\"number\">20</span>);</span><br><span class=\"line\">plt.title(<span class=\"string\">'Top 10 countries'</span>, fontsize=<span class=\"number\">30</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/2020030407434626.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/2020030407440185.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>自杀率排在前10的国家为 俄罗斯（欧洲）、 匈牙利（欧洲）、乌克兰（欧洲）、 克罗地亚 （欧洲）、日本（亚洲）、澳大利亚 （大洋洲）、芬兰 （欧洲）、古巴 （美洲）、比利时（欧洲）、 瑞士（欧洲）</strong></p>\n<p><strong>自杀人数排前10的国家为 俄罗斯（欧洲）、美国（美洲）、日本（亚洲）、乌克兰（欧洲）、德国（欧洲）、法国（欧洲）、 巴西（美洲）、波兰（欧洲）、泰国 （亚洲）、英国（欧洲）<br>可以发现欧洲国家的自杀人数和自杀率都非常高，例如俄罗斯、乌克兰、英国等。 也可以发现俄罗斯、日本等国家高居自杀率都偏高，这些国家是GDP、就业、奢侈品等方面最强大的国家，并且经济实力也位于世界前列，而导致自杀率高的一个客观原因是人口基数大，主观原因可能是生活节奏飞快，生活代价很高,失业率严重、人际关系紧张等。</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>, <span class=\"number\">16</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#总人口的各个年龄段的性别分布</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">311</span>)</span><br><span class=\"line\">sns.barplot(x=<span class=\"string\">'sex'</span>, y=<span class=\"string\">'population'</span>, hue=<span class=\"string\">'age'</span>, data=df, palette=<span class=\"string\">\"Greens\"</span>)  <span class=\"comment\">#hue按年龄分组</span></span><br><span class=\"line\">plt.xticks(ha=<span class=\"string\">'right'</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Population'</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Sex'</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">\"不同年龄段的男、女总人口数\"</span>)</span><br><span class=\"line\">plt.legend(fontsize=<span class=\"number\">14</span>, loc=<span class=\"string\">'best'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#自杀人数的各个年龄段的性别分布</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">312</span>)</span><br><span class=\"line\">sns.barplot(x=<span class=\"string\">'sex'</span>, y=<span class=\"string\">'suicides_no'</span>, hue=<span class=\"string\">'age'</span>, data=df, palette=<span class=\"string\">\"Greens\"</span>)</span><br><span class=\"line\">plt.xticks(ha=<span class=\"string\">'right'</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'suicides incidences'</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Sex'</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">\"不同年龄段的男、女自杀人口数\"</span>)</span><br><span class=\"line\">plt.legend(fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#自杀率（放大1000倍）的各个年龄段的性别分布</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">313</span>)</span><br><span class=\"line\">sns.barplot(x=<span class=\"string\">'sex'</span>, y=<span class=\"string\">'suicidesper100k'</span>, hue=<span class=\"string\">'age'</span>, data=df,palette=<span class=\"string\">\"Greens\"</span>)</span><br><span class=\"line\">plt.xticks(ha=<span class=\"string\">'right'</span>, fontsize=<span class=\"number\">20</span>);</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'suicidesper100k'</span>,fontsize=<span class=\"number\">20</span>);</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Sex'</span>,fontsize=<span class=\"number\">20</span>);</span><br><span class=\"line\">plt.title(<span class=\"string\">\"不同年龄段的男、女自杀率\"</span>)</span><br><span class=\"line\">plt.legend(fontsize=<span class=\"number\">14</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplots_adjust(top=<span class=\"number\">1.2</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304080041244.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/20200304080101563.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/20200304080122305.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>图1为 各个不同年龄段的男、女总人口数据柱状图。 就总人口而言 各个年龄段的男女比例差不多。<br>图2为 各个不同年龄段的男、女自杀人口数据柱状图。 可以很明显的看出男性的自杀人数远远大于女性自杀人数。 其可能的原因男性所承受的压力要多于女性，精神方面会变得脆弱，并会导致身体不健康以及精神不健康。<br>图3为 各个不同年龄段的男、女自杀率人口数据柱状图。 就75+，也就是老年阶段，从侧面也反映出老龄化的问题。 在老龄化进程加速的状况下，社会保障体系和社会经济文化的发展难以满足老年人的物质和精神需求， 多重矛盾造就了本该安享晚年的老年人，出现了比年轻人更严重的生存和精神压力。 所以，老年人的生存现状需要受到重视，应该不断出台老年人的保障措施，来保障老年人的老年生活。</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">16</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 具体按性别和年份 来看 男女的自杀率</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">311</span>)</span><br><span class=\"line\">sns.lineplot(x=<span class=\"string\">'year'</span>, y=<span class=\"string\">'suicidesper100k'</span>, hue=<span class=\"string\">'sex'</span>, data=df, palette=<span class=\"string\">\"hot\"</span>)  <span class=\"comment\">#hue按年龄分组</span></span><br><span class=\"line\">plt.xticks(ha=<span class=\"string\">'right'</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'suicidesper100k'</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'year'</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.legend(fontsize=<span class=\"number\">14</span>, loc=<span class=\"string\">'best'</span>)  </span><br><span class=\"line\">plt.title(<span class=\"string\">\"性别年份与自杀率关系图\"</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/2020030408021812.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>图为 具体按性别和年份 来看 男女的自杀率 1995年-2013年男性自杀率远远大于女性。 女性自杀率水平在0.005%左右，男性自杀率水平在0.02%左右，男性自杀率约是女性的4倍。从时间来看，在这区间，全球范围综合自杀率并没有出现明显的下降<br>结合分析，在全球范围内，男性自杀率高于女性，约为女性自杀率的4倍左右。在现代社会中男性承担的社会责任相对较大，相应的压力也会增加。所以一个国家应该关注于提升人民生活质量，健全保障体系。在每个家庭面对突发的困难是能够提供一定的保障，例如失业，生病，意外事故等。<br>全球范围内，年龄越大的人群自杀率相对较高。在现在全球人口老龄化的趋势下，这种情况无疑更加严峻。关于老年人群的生活的物质条件需要改善，其心理更需要梳理与关注。</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#选出year列并且去除重复的年份</span></span><br><span class=\"line\">year = originaldata.groupby(<span class=\"string\">'year'</span>).year.unique()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#各个年份的自杀人数汇总</span></span><br><span class=\"line\"><span class=\"comment\">#使用seaborn进行可视化,输入的数据必须为dataframe</span></span><br><span class=\"line\">totalpyear = pd.DataFrame(originaldata.groupby(<span class=\"string\">'year'</span>).suicides_no.sum())   </span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(year.index[<span class=\"number\">0</span>:<span class=\"number\">31</span>], totalpyear[<span class=\"number\">0</span>:<span class=\"number\">31</span>], color=col[<span class=\"number\">18</span>])  <span class=\"comment\">#选取范围为[0:31]  1985年到2015年</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'year'</span>, fontsize=<span class=\"number\">15</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Total number of suicides in the world'</span>, fontsize=<span class=\"number\">15</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://img-blog.csdnimg.cn/20200304080310204.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p><strong>世界自杀人数趋势2000年之前逐步上升，2000年后呈现缓慢下降趋势 在2000年之前，人们所处的地区条件乏善可陈，人群受教育程度偏低，社会动荡，经济发展水平不高。 之后，随着科技的进步以及社会经济不断发展，社会更加安稳。混乱、贫穷、饥饿的现象变少，人们的的焦虑有改善。各国政府在医疗保健上的投入和家庭护理的提升也会使自杀趋势降低。</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure(figsize=(<span class=\"number\">20</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 自杀率（放大1000倍）的分布情况，y轴为个数</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">121</span>)</span><br><span class=\"line\">plt.hist(df.suicidesper100k, bins=<span class=\"number\">30</span>, color=col[<span class=\"number\">18</span>])   <span class=\"comment\">#bins:条形数</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Suicides per 100K of population'</span>, fontsize=<span class=\"number\">25</span>)</span><br><span class=\"line\">plt.xticks(rotation = <span class=\"number\">0</span>,                 fontsize = <span class=\"number\">20</span>)  </span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'count'</span>, fontsize=<span class=\"number\">25</span>)</span><br><span class=\"line\">plt.yticks(                              fontsize = <span class=\"number\">20</span>)   </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 年人均国内生产总值的分布情况，y轴为个数</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">122</span>)</span><br><span class=\"line\">plt.hist(df.GDPpcapita, bins=<span class=\"number\">30</span>, color=col[<span class=\"number\">7</span>])</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'GDP'</span>, fontsize=<span class=\"number\">25</span>)</span><br><span class=\"line\">plt.xticks(rotation = <span class=\"number\">0</span>,fontsize = <span class=\"number\">20</span>)  </span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'count'</span>, fontsize=<span class=\"number\">25</span>)</span><br><span class=\"line\">plt.yticks(fontsize = <span class=\"number\">20</span>)   </span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304080429224.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># suicides：“GDP年度国内生产总值（美元）”，“雇员补偿%”，“失业人数%”，“预期寿命” 按“年份”分组</span></span><br><span class=\"line\">suicides = df[[<span class=\"string\">'year'</span>, <span class=\"string\">'GDPpyear'</span>, <span class=\"string\">'Selfemployed'</span>, <span class=\"string\">'Unemployment'</span>, <span class=\"string\">'Lifeexpectancy'</span>]].groupby(<span class=\"string\">'year'</span>).mean()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># suicides['Suicides'] 为各年份的自杀率总数</span></span><br><span class=\"line\">suicides[<span class=\"string\">'Suicides'</span>] = df[[<span class=\"string\">'country'</span>, <span class=\"string\">'year'</span>, <span class=\"string\">'suicidesper100k'</span>]].groupby(<span class=\"string\">'year'</span>).sum()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># suicides.index ：从1995到2013年，   </span></span><br><span class=\"line\"><span class=\"comment\"># GDPpyear/suicides.GDPpyear.max()  ： GDP年度国内生产总值/最大GDP年度国内生产总值</span></span><br><span class=\"line\">plt.plot(suicides.index, suicides.GDPpyear/suicides.GDPpyear.max(), color=col[<span class=\"number\">1</span>])  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># suicides.Unemployment：失业总人数(占劳动力总数的百分比)(模拟劳工组织估计数)</span></span><br><span class=\"line\"><span class=\"comment\"># suicides.Unemployment.max()：最大值</span></span><br><span class=\"line\">plt.plot(suicides.index, suicides.Unemployment/suicides.Unemployment.max(), color=col[<span class=\"number\">7</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># suicides.Lifeexpectancy  ； 各年的预期寿命</span></span><br><span class=\"line\">plt.plot(suicides.index, suicides.Lifeexpectancy/suicides.Lifeexpectancy.max(), color=col[<span class=\"number\">14</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># suicides.Suicides ：各年的自杀率</span></span><br><span class=\"line\">plt.plot(suicides.index, suicides.Suicides/suicides.Suicides.max(), color=col[<span class=\"number\">17</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">plt.legend(</span><br><span class=\"line\">            [<span class=\"string\">'global average GDPpyear'</span>,                            <span class=\"comment\">#红线</span></span><br><span class=\"line\">            <span class=\"string\">'global average Unemployment'</span>,                         <span class=\"comment\">#黄线</span></span><br><span class=\"line\">            <span class=\"string\">'global average Life expectancy'</span>,                      <span class=\"comment\">#绿线</span></span><br><span class=\"line\">            <span class=\"string\">'Total suicides per 100k'</span>], fontsize=<span class=\"number\">14</span>, loc=<span class=\"string\">'best'</span>    <span class=\"comment\">#蓝线</span></span><br><span class=\"line\">            )</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Normalized'</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'year'</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">\"各年份全球平均GDP、平均失业率、平均预期寿命、平均自杀率趋势图\"</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304080534555.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>从图中可以看出</strong><br>自1995 - 2013年，</p>\n<ol>\n<li>全球的GDP不断上涨，1995年到2000年缓慢上涨，2000年以后经济增长的势头更强；受到金融危机的影响，2008年经济下滑后又开始增长。</li>\n<li>全球的失业率也随经济，社会发展，1995-2008逐年降低，之后又攀升。</li>\n<li>全球的人预期寿命也随着经济的不断发展逐年上升，人民生活水平提高。</li>\n<li>全球的整体自杀率是呈下降趋势的，背后的原因可能是社会的安稳，国家政府的干预，各国政府在医疗保健上的投入和家庭护理的提升。</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">corr = total.corr() <span class=\"comment\">#相关系数矩阵，即给出了任意两个变量之间的相关系数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 相关矩阵的上三角部分与下三角对称。因此，热图不需要显示整个矩阵。在下一步隐藏上三角形。</span></span><br><span class=\"line\"><span class=\"comment\"># 设置mask隐藏上三角</span></span><br><span class=\"line\"><span class=\"comment\"># np.zeros_like() 返回一个零数组，其形状和类型与给定的数组相同。</span></span><br><span class=\"line\"><span class=\"comment\"># 该 dtype=np.bool 参数会覆盖数据类型，因此我们的数组是一个布尔数组。</span></span><br><span class=\"line\"><span class=\"comment\"># np.triu_indices_from(mask) 返回数组上三角形的索引。</span></span><br><span class=\"line\"><span class=\"comment\"># 现在，我们将上三角形设置为True。 mask[np.triu_indices_from(mask)]= True</span></span><br><span class=\"line\">mask = np.zeros_like(corr, dtype=np.bool)</span><br><span class=\"line\">mask[np.triu_indices_from(mask)] = <span class=\"literal\">True</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 在Seaborn中创建热图</span></span><br><span class=\"line\">f, ax = plt.subplots(figsize=(<span class=\"number\">10</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"><span class=\"comment\"># 生成自定义发散颜色图</span></span><br><span class=\"line\">cmap = sns.diverging_palette(<span class=\"number\">220</span>, <span class=\"number\">10</span>, as_cmap=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 绘制热图</span></span><br><span class=\"line\"><span class=\"comment\"># 数据为 corr</span></span><br><span class=\"line\"><span class=\"comment\"># vmax,vmin:分别是热力图的颜色取值最大和最小范围</span></span><br><span class=\"line\"><span class=\"comment\"># center:数据表取值有差异时，设置热力图的色彩中心对齐值；通过设置center值，可以调整生成的图像颜色的整体深浅</span></span><br><span class=\"line\"><span class=\"comment\"># square:设置热力图矩阵小块形状，默认值是False</span></span><br><span class=\"line\"><span class=\"comment\"># linewidths(矩阵小块的间隔),</span></span><br><span class=\"line\"><span class=\"comment\"># cbar_kws:热力图侧边绘制颜色刻度条时，相关字体设置，默认值是None</span></span><br><span class=\"line\">sns.heatmap(corr, mask=mask, cmap=cmap, vmax=<span class=\"number\">1</span>, vmin=<span class=\"number\">-1</span>, center=<span class=\"number\">0</span>,  </span><br><span class=\"line\">            square=<span class=\"literal\">True</span>, linewidths=<span class=\"number\">0.2</span>, cbar_kws=&#123;<span class=\"string\">\"shrink\"</span>: <span class=\"number\">0.8</span>&#125;)</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304080712702.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"3-数据预处理\"><a href=\"#3-数据预处理\" class=\"headerlink\" title=\"3.数据预处理\"></a>3.数据预处理</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 对使用互联网的个人(占人口的百分比) 用最小值填充 在原数据直接修改</span></span><br><span class=\"line\">total.Internetusers.fillna(total.Internetusers. min(), inplace=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 对难民人口用8填充</span></span><br><span class=\"line\">total.Refugees.fillna(total.Refugees. min(), inplace=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#对雇员补偿(占开支的百分比)用均值填充</span></span><br><span class=\"line\">total.employeecompensation.fillna(total.employeecompensation.mean(), inplace=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 对总人口用均值填充</span></span><br><span class=\"line\">total.population.fillna(total.population.mean(), inplace=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>自杀风险的二元分类</strong></p>\n<p>对自杀数据进行二元分类，根据 自杀率（扩大1000倍） 作为高/低自杀风险来划分风险等级。<br>在“total”data frame中添加一个额外的列作为‘risk’。</p>\n<ul>\n<li>Suicides &lt; mean(Suicides) –&gt; 低风险 –&gt; class 0</li>\n<li>Suicides &gt; mean(Suicides) –&gt; 高风险 –&gt; class 1</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 小于平均值的为低风险，大于平均值的为高风险</span></span><br><span class=\"line\">total[<span class=\"string\">'risk'</span>] = total.Suicides.copy()</span><br><span class=\"line\">total[<span class=\"string\">'risk'</span>] = np.where(total.risk &lt; total.Suicides.mean(), <span class=\"number\">0</span>, <span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure(figsize=(<span class=\"number\">16</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">121</span>)</span><br><span class=\"line\">plt.hist(total.risk, color=col[<span class=\"number\">8</span>])</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'counts'</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Suicide risk'</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">\"自杀高低风险数量\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">122</span>)</span><br><span class=\"line\">sns.distplot(total.Suicides[total.risk == <span class=\"number\">0</span>], bins=<span class=\"number\">10</span>)</span><br><span class=\"line\">sns.distplot(total.Suicides[total.risk == <span class=\"number\">1</span>], bins=<span class=\"number\">20</span>)  </span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Suicides'</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">\"自杀高低风险分布情况\"</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304080922287.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 对国家进行 标准化标签，将标签值统一转换成range(标签值个数-1)范围内</span></span><br><span class=\"line\"><span class=\"comment\"># 相当于fit(X).transform(X),意思就是先进行fit(),进行数据拟合，然后在进行transform() 进行标准化处理</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> LabelEncoder</span><br><span class=\"line\">le = LabelEncoder()</span><br><span class=\"line\">total.country = le.fit_transform(total.country)  </span><br><span class=\"line\">total.country.unique()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 为建立模型准备数据</span></span><br><span class=\"line\"><span class=\"comment\"># totalfeatures 数据的 11个特征</span></span><br><span class=\"line\"><span class=\"comment\"># array和asarray都可以将结构数据转化为ndarray   </span></span><br><span class=\"line\"><span class=\"comment\"># ndarray是Numpy中的数据结构，是一个多维数组，可以理解为矩阵，具有矢量运算能力，快速、节省空间</span></span><br><span class=\"line\"></span><br><span class=\"line\">X = np.asarray(total[totalfeatures])</span><br><span class=\"line\">y = np.asarray(total[<span class=\"string\">'risk'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 对数据应用标准定标器，因为ML算法的工作假设是数据是正态分布的</span></span><br><span class=\"line\"><span class=\"comment\"># 标准化数据</span></span><br><span class=\"line\"><span class=\"comment\"># sklearn.preprocessing.StandardScaler() 可保存训练集中的均值、方差参数，然后直接用于转换测试集数据。</span></span><br><span class=\"line\">scaler = StandardScaler()</span><br><span class=\"line\">scaler.fit(X)</span><br><span class=\"line\">X_scaled = scaler.transform(X)</span><br></pre></td></tr></table></figure>\n<p><strong>划分训练集、测试集和验证集</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 将数据集拆分为训练集和测试集 576行 11个特征</span></span><br><span class=\"line\"><span class=\"comment\"># 首先将该数据3/4作为训练集，1/4作为测试集；再由训练集划分1/5作为验证集</span></span><br><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=<span class=\"number\">0.25</span>, random_state=<span class=\"number\">4</span>)</span><br><span class=\"line\">X_train,X_valid,y_train,y_valid=train_test_split(X_train,y_train,test_size=<span class=\"number\">0.2</span>,random_state=<span class=\"number\">4</span>)</span><br><span class=\"line\">print(<span class=\"string\">'Train set:'</span>, X_train.shape, y_train.shape)</span><br><span class=\"line\">print(<span class=\"string\">'Test set:'</span>, X_test.shape, y_test.shape)</span><br><span class=\"line\">print(<span class=\"string\">'Test set:'</span>, X_valid.shape, y_valid.shape)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># GDP = 雇员报酬 + 固定资产消耗 + 生产税和进口税净额 + 营业盈余</span></span><br><span class=\"line\"><span class=\"comment\"># 这里面的“雇员报酬”仅仅只是GDP其中的一个组成部分</span></span><br><span class=\"line\">ax1 = total[total[<span class=\"string\">'risk'</span>] == <span class=\"number\">1</span>][<span class=\"number\">0</span>:<span class=\"number\">200</span>].plot(kind=<span class=\"string\">'scatter'</span>, x=<span class=\"string\">'GDPpcapita'</span>, y=<span class=\"string\">'employeecompensation'</span>, color=<span class=\"string\">'DarkRed'</span>,</span><br><span class=\"line\">                                            label=<span class=\"string\">'high risk'</span>, figsize=(<span class=\"number\">6</span>, <span class=\"number\">5</span>), fontsize=<span class=\"number\">12</span>)</span><br><span class=\"line\">total[total[<span class=\"string\">'risk'</span>] == <span class=\"number\">0</span>][<span class=\"number\">0</span>:<span class=\"number\">200</span>].plot(kind=<span class=\"string\">'scatter'</span>, x=<span class=\"string\">'GDPpcapita'</span>, y=<span class=\"string\">'employeecompensation'</span>, color=<span class=\"string\">'DarkBlue'</span>,</span><br><span class=\"line\">                                            label=<span class=\"string\">'low risk'</span>, ax=ax1)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'employeecompensation'</span>, fontsize=<span class=\"number\">16</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'GDP per capita'</span>, fontsize=<span class=\"number\">16</span>)</span><br><span class=\"line\">plt.legend(fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 预期寿命 和 贡献型家庭工人总人数(占总就业人数的百分比) 的高低风险</span></span><br><span class=\"line\">ax1 = total[total[<span class=\"string\">'risk'</span>] == <span class=\"number\">1</span>][<span class=\"number\">0</span>:<span class=\"number\">200</span>].plot(kind=<span class=\"string\">'scatter'</span>, x=<span class=\"string\">'Lifeexpectancy'</span>, y=<span class=\"string\">'Selfemployed'</span>, color=<span class=\"string\">'DarkRed'</span>,</span><br><span class=\"line\">                                            label=<span class=\"string\">'high risk'</span>, figsize=(<span class=\"number\">6</span>, <span class=\"number\">5</span>), fontsize=<span class=\"number\">12</span>)</span><br><span class=\"line\">total[total[<span class=\"string\">'risk'</span>] == <span class=\"number\">0</span>][<span class=\"number\">0</span>:<span class=\"number\">200</span>].plot(kind=<span class=\"string\">'scatter'</span>, x=<span class=\"string\">'Lifeexpectancy'</span>, y=<span class=\"string\">'Selfemployed'</span>, color=<span class=\"string\">'DarkBlue'</span>,</span><br><span class=\"line\">                                            label=<span class=\"string\">'low risk'</span>, ax=ax1);</span><br><span class=\"line\"></span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Selfemployed'</span>, fontsize=<span class=\"number\">16</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Lifeexpectancy'</span>, fontsize=<span class=\"number\">16</span>)</span><br><span class=\"line\">plt.legend(fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 人均国内生产总值(美元) 和 失业总人数(占劳动力总数的百分比) 的高低风险</span></span><br><span class=\"line\">ax1 = total[total[<span class=\"string\">'risk'</span>] == <span class=\"number\">1</span>][<span class=\"number\">0</span>:<span class=\"number\">200</span>].plot(kind=<span class=\"string\">'scatter'</span>, x=<span class=\"string\">'GDPpcapita'</span>, y=<span class=\"string\">'Unemployment'</span>, color=<span class=\"string\">'DarkRed'</span>,</span><br><span class=\"line\">                                            label=<span class=\"string\">'high risk'</span>, figsize=(<span class=\"number\">6</span>, <span class=\"number\">5</span>), fontsize=<span class=\"number\">12</span>);</span><br><span class=\"line\">total[total[<span class=\"string\">'risk'</span>] == <span class=\"number\">0</span>][<span class=\"number\">0</span>:<span class=\"number\">200</span>].plot(kind=<span class=\"string\">'scatter'</span>, x=<span class=\"string\">'GDPpcapita'</span>, y=<span class=\"string\">'Unemployment'</span>, color=<span class=\"string\">'DarkBlue'</span>,</span><br><span class=\"line\">                                            label=<span class=\"string\">'low risk'</span>, ax=ax1);</span><br><span class=\"line\"></span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Unemployment'</span>, fontsize=<span class=\"number\">16</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'GDP per capita'</span>, fontsize=<span class=\"number\">16</span>)</span><br><span class=\"line\">plt.legend(fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304081321594.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>图1为 人均GDP 和 雇员的报酬（工资）(占开支的百分比) 的关于自杀率高低的一个分类。</strong></p>\n<p>  雇员的报酬（工资） 是 人均GDP 的一部分，人均gdp集中在5000-50000美元；而工资占开销的 10%-30%，在人均gdp大致相同的情况下，工资越高，那么自杀率相对会低，但是即使人均gdp很高的情况下，工资如果很低，自杀率也会偏高。</p>\n<p><strong>图2为 预期寿命 和 供养家庭职工总人数(占总就业人数的百分比) 的高低风险</strong></p>\n<p>  预期寿命分布在70-82岁，而在预期寿命相同的情况下，若供养家庭职工总人数多，则自杀风险相对会低</p>\n<p><strong>图3为 人均国内生产总值(美元) 和 失业总人数(占劳动力总数的百分比) 的高低风险</strong><br>  人均gdp越高，自杀率还是较低的；在人均gdp较低（0-15000美元）下，失业的人数反而不算高；但在中产和富裕阶级中，失业人数越高，自杀风险更大。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 关于年份的高低自杀风险</span></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">30</span>, <span class=\"number\">30</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">4</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">sns.distplot(total[total.columns[<span class=\"number\">0</span>]][total.risk == <span class=\"number\">0</span>], label=<span class=\"string\">'low risk'</span>)</span><br><span class=\"line\">sns.distplot(total[total.columns[<span class=\"number\">0</span>]][total.risk == <span class=\"number\">1</span>], label=<span class=\"string\">'high risk'</span>)       </span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">'best'</span>, fontsize=<span class=\"number\">18</span>)  </span><br><span class=\"line\">plt.xlabel(total.columns[<span class=\"number\">0</span>], fontsize=<span class=\"number\">18</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304081506392.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"4-建模\"><a href=\"#4-建模\" class=\"headerlink\" title=\"4.建模\"></a>4.建模</h2><p>根据他的要求，使用逻辑回归、决策树、随机森林这三种模型，并且对比找到最好的分类模型。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LogisticRegression</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> recall_score,accuracy_score</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> precision_recall_fscore_support</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> confusion_matrix, classification_report</span><br><span class=\"line\"></span><br><span class=\"line\">LR = LogisticRegression(C=<span class=\"number\">0.001</span>, solver=<span class=\"string\">'liblinear'</span>).fit(X_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 预测类别:0还是1</span></span><br><span class=\"line\">yLRhat = LR.predict(X_valid)</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 预测 0或1的概率（例如 [0.54689436, 0.45310564] 预测出来为0）</span></span><br><span class=\"line\">yLRhat_prob = LR.predict_proba(X_valid)</span><br><span class=\"line\"></span><br><span class=\"line\">cm = confusion_matrix(y_valid, yLRhat)</span><br><span class=\"line\">print(<span class=\"string\">'\\n confusion matrix：混淆矩阵 \\n'</span>, cm)</span><br><span class=\"line\">print(<span class=\"string\">'此时模型准确率为:'</span>,accuracy_score(y_valid, yLRhat))</span><br><span class=\"line\">print(<span class=\"string\">'********************************************************'</span>)</span><br><span class=\"line\">print(<span class=\"string\">'\\n'</span>)</span><br><span class=\"line\">print(<span class=\"string\">'逻辑回归模型的分类报告\\n'</span>, classification_report(y_valid, yLRhat))</span><br><span class=\"line\"></span><br><span class=\"line\">skplt.metrics.plot_confusion_matrix(y_valid,yLRhat,normalize=<span class=\"literal\">True</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304082158485.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/20200304082224591.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>这里的超参数调整我使用网格搜索，因为逻辑回归的超参数较少且模型训练的比较快,而且网格搜索自带就有交叉验证。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> GridSearchCV</span><br><span class=\"line\"></span><br><span class=\"line\">param=&#123;<span class=\"string\">\"tol\"</span>:[<span class=\"number\">1e-4</span>, <span class=\"number\">1e-3</span>,<span class=\"number\">1e-2</span>], <span class=\"string\">\"C\"</span>:[<span class=\"number\">0.4</span>, <span class=\"number\">0.6</span>, <span class=\"number\">0.8</span>]&#125;</span><br><span class=\"line\">grid = GridSearchCV(LogisticRegression(),param_grid=param, cv=<span class=\"number\">5</span>)<span class=\"comment\">#这里是5折交叉验证</span></span><br><span class=\"line\">grid.fit(X_train,y_train)</span><br><span class=\"line\">print(grid.best_params_)</span><br><span class=\"line\">print(grid.best_score_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#得到最好的逻辑回归分类器</span></span><br><span class=\"line\">best_LR=grid.best_estimator_ </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#进行训练、预测</span></span><br><span class=\"line\">best_LR.fit(X_train,y_train)</span><br><span class=\"line\">pred=best_LR.predict(X_valid)</span><br><span class=\"line\"></span><br><span class=\"line\">cm = confusion_matrix(y_valid, pred)</span><br><span class=\"line\">print(<span class=\"string\">'\\n confusion matrix：混淆矩阵 \\n'</span>, cm)</span><br><span class=\"line\">print(<span class=\"string\">'最好的逻辑回归模型准确率为:'</span>,accuracy_score(y_valid, pred))</span><br><span class=\"line\">print(<span class=\"string\">'********************************************************'</span>)</span><br><span class=\"line\">print(<span class=\"string\">'\\n'</span>)</span><br><span class=\"line\">print(<span class=\"string\">'最好的逻辑回归模型的分类报告\\n'</span>, classification_report(y_valid, pred))</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304082301920.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>逻辑回归分类效果并不好，再来看看决策树</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> accuracy_score</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> confusion_matrix, classification_report</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 决策树学习</span></span><br><span class=\"line\"><span class=\"comment\"># 函数为创建一个决策树模型</span></span><br><span class=\"line\"><span class=\"comment\"># criterion：gini或者entropy,前者是基尼系数，后者是信息熵。</span></span><br><span class=\"line\"><span class=\"comment\"># max_depth：  int or None, optional (default=None) 设置决策随机森林中的决策树的最大深度，深度越大，越容易过拟合，推荐树的深度为：5-20之间。</span></span><br><span class=\"line\"><span class=\"comment\"># max_leaf_nodes： 通过限制最大叶子节点数，可以防止过拟合，默认是\"None”，即不限制最大的叶子节点数。</span></span><br><span class=\"line\">DT = DecisionTreeClassifier(criterion=<span class=\"string\">\"entropy\"</span>, max_depth=<span class=\"number\">7</span>, max_leaf_nodes=<span class=\"number\">30</span>)</span><br><span class=\"line\">DT.fit(X_train, y_train)</span><br><span class=\"line\">ydthat = DT.predict(X_valid)</span><br><span class=\"line\"></span><br><span class=\"line\">print(<span class=\"string\">'***决策树模型***'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#决策树模型性能评估</span></span><br><span class=\"line\">print(<span class=\"string\">'验证集上的准确率:'</span>, DT.score(X_valid, y_valid))</span><br><span class=\"line\">print(<span class=\"string\">'训练集上的准确率:'</span>, DT.score(X_train, y_train))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 混淆矩阵</span></span><br><span class=\"line\">print(<span class=\"string\">'CM\\n'</span>, confusion_matrix(y_valid, ydthat))</span><br><span class=\"line\">print(<span class=\"string\">'********************************************************'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">print(<span class=\"string\">'决策树模型的分类报告\\n'</span>, classification_report(y_valid, ydthat))</span><br><span class=\"line\"></span><br><span class=\"line\">DTfeat_importance = DT.feature_importances_</span><br><span class=\"line\">DTfeat_importance = pd.DataFrame([totalfeatures, DT.feature_importances_]).T</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 特征重要性排序</span></span><br><span class=\"line\">print(<span class=\"string\">\"特征重要性排名如下:\"</span>)</span><br><span class=\"line\">print(<span class=\"string\">f'\\n一共有<span class=\"subst\">&#123;DT.n_features_&#125;</span>个特征'</span>)</span><br><span class=\"line\">print(DTfeat_importance.sort_values(by=<span class=\"number\">1</span>, ascending=<span class=\"literal\">False</span>))</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304082344979.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 通过cv_results观察过程并做图</span></span><br><span class=\"line\">max_depth=np.arange(<span class=\"number\">0</span>,<span class=\"number\">20</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">max_leaf_nodes=np.arange(<span class=\"number\">0</span>,<span class=\"number\">30</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">min_samples_leaf =np.arange(<span class=\"number\">0</span>,<span class=\"number\">20</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">param1= &#123;<span class=\"string\">'criterion'</span>:[<span class=\"string\">'entropy'</span>],<span class=\"string\">'max_depth'</span>:max_depth&#125;</span><br><span class=\"line\">param2= &#123;<span class=\"string\">'criterion'</span>:[<span class=\"string\">'entropy'</span>],<span class=\"string\">'min_samples_leaf'</span>:min_samples_leaf&#125;</span><br><span class=\"line\">param3= &#123;<span class=\"string\">'criterion'</span>:[<span class=\"string\">'entropy'</span>],<span class=\"string\">'max_leaf_nodes'</span>:max_leaf_nodes&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">clf1 = GridSearchCV(DecisionTreeClassifier(),param_grid=param1,cv=<span class=\"number\">6</span>)</span><br><span class=\"line\">clf1.fit(X_train,y_train)</span><br><span class=\"line\"></span><br><span class=\"line\">clf2 = GridSearchCV(DecisionTreeClassifier(),param_grid=param2,cv=<span class=\"number\">6</span>)</span><br><span class=\"line\">clf2.fit(X_train,y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">clf3 = GridSearchCV(DecisionTreeClassifier(),param_grid=param3,cv=<span class=\"number\">6</span>)</span><br><span class=\"line\">clf3.fit(X_train,y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">fig = plt.figure()</span><br><span class=\"line\">ax = fig.add_subplot(<span class=\"number\">311</span>)</span><br><span class=\"line\">ax.plot(min_samples_leaf,clf2.cv_results_[<span class=\"string\">'mean_test_score'</span>],<span class=\"string\">'g*-'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'决策树模型网格搜索的训练过程'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">ax = fig.add_subplot(<span class=\"number\">312</span>)</span><br><span class=\"line\">ax.plot(max_depth,clf1.cv_results_[<span class=\"string\">'mean_test_score'</span>],<span class=\"string\">'g*-'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ax = fig.add_subplot(<span class=\"number\">313</span>)</span><br><span class=\"line\">ax.plot(max_leaf_nodes,clf3.cv_results_[<span class=\"string\">'mean_test_score'</span>],<span class=\"string\">'g*-'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304082503795.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">best_DT = DecisionTreeClassifier(criterion=<span class=\"string\">\"entropy\"</span>, max_depth=<span class=\"number\">15</span>, max_leaf_nodes=<span class=\"number\">25</span>,min_samples_leaf=<span class=\"number\">4</span>)</span><br><span class=\"line\">best_DT.fit(X_train, y_train)</span><br><span class=\"line\">ydthat =best_DT.predict(X_valid)</span><br><span class=\"line\"></span><br><span class=\"line\">print(<span class=\"string\">'***决策树模型***'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#决策树模型性能评估</span></span><br><span class=\"line\">print(<span class=\"string\">'验证集上的准确率:'</span>,best_DT.score(X_valid, y_valid))</span><br><span class=\"line\">print(<span class=\"string\">'训练集上的准确率:'</span>,best_DT.score(X_train, y_train))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 混淆矩阵</span></span><br><span class=\"line\">print(<span class=\"string\">'CM\\n'</span>, confusion_matrix(y_valid, ydthat))</span><br><span class=\"line\">print(<span class=\"string\">'********************************************************'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">print(<span class=\"string\">'决策树模型的分类报告\\n'</span>, classification_report(y_valid, ydthat))</span><br><span class=\"line\"></span><br><span class=\"line\">DTfeat_importance = best_DT.feature_importances_</span><br><span class=\"line\">DTfeat_importance = pd.DataFrame([totalfeatures, DT.feature_importances_]).T</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 特征重要性排序</span></span><br><span class=\"line\">print(<span class=\"string\">\"特征重要性排名如下:\"</span>)</span><br><span class=\"line\">print(<span class=\"string\">f'\\n一共有<span class=\"subst\">&#123;best_DT.n_features_&#125;</span>个特征'</span>)</span><br><span class=\"line\">print(DTfeat_importance.sort_values(by=<span class=\"number\">1</span>, ascending=<span class=\"literal\">False</span>))</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/2020030408260675.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/2020030408263517.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 随机森林可以视为多颗决策树的集成，鲁棒性更强，泛化能力更好，不易产生过拟合现象。但是噪声比较大的情况下会过拟合。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> RandomForestClassifier</span><br><span class=\"line\"></span><br><span class=\"line\">random_forest = RandomForestClassifier(n_estimators=<span class=\"number\">20</span>, max_depth=<span class=\"number\">10</span>, min_samples_split=<span class=\"number\">2</span>, min_samples_leaf=<span class=\"number\">5</span>,</span><br><span class=\"line\">                                       max_leaf_nodes=<span class=\"number\">20</span>, max_features=len(totalfeatures)) </span><br><span class=\"line\"></span><br><span class=\"line\">random_forest.fit(X_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\">yrfhat = random_forest.predict(X_valid)</span><br><span class=\"line\">feat_importance = random_forest.feature_importances_</span><br><span class=\"line\">rffeat_importance = pd.DataFrame([totalfeatures, random_forest.feature_importances_]).T</span><br><span class=\"line\"></span><br><span class=\"line\">print(<span class=\"string\">'******************Random forest classifier**************'</span>)</span><br><span class=\"line\">print(<span class=\"string\">'训练集上的准确率'</span>, random_forest.score(X_train, y_train))</span><br><span class=\"line\">print(<span class=\"string\">'验证集上的准确率'</span>, random_forest.score(X_valid,y_valid))</span><br><span class=\"line\">print(<span class=\"string\">'混淆矩阵\\n'</span>, confusion_matrix(y_valid, yrfhat))</span><br><span class=\"line\">print(<span class=\"string\">'********************************************************'</span>)</span><br><span class=\"line\">print(<span class=\"string\">'随机森林的分类报告\\n'</span>, classification_report(y_valid, yrfhat))</span><br><span class=\"line\">print(rffeat_importance.sort_values(by=<span class=\"number\">1</span>, ascending=<span class=\"literal\">False</span>))</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#我们首先对n_estimators进行网格搜索：</span></span><br><span class=\"line\">param_test1 = &#123;<span class=\"string\">'n_estimators'</span>:[<span class=\"number\">50</span>,<span class=\"number\">120</span>,<span class=\"number\">160</span>,<span class=\"number\">200</span>,<span class=\"number\">250</span>]&#125;</span><br><span class=\"line\">gsearch1 = GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_test1,cv=<span class=\"number\">5</span>)</span><br><span class=\"line\">gsearch1.fit(X_train,y_train)</span><br><span class=\"line\">print( gsearch1.best_params_, gsearch1.best_score_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#接着我们对决策树最大深度max_depth和内部节点再划分所需最小样本数min_samples_split进行网格搜索。</span></span><br><span class=\"line\">param_test2 = &#123;<span class=\"string\">'max_depth'</span>:[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">7</span>,<span class=\"number\">9</span>,<span class=\"number\">11</span>,<span class=\"number\">13</span>,<span class=\"number\">20</span>],<span class=\"string\">'min_samples_split'</span>:[<span class=\"number\">5</span>,<span class=\"number\">10</span>,<span class=\"number\">25</span>,<span class=\"number\">50</span>,<span class=\"number\">100</span>,<span class=\"number\">120</span>,<span class=\"number\">150</span>]&#125;</span><br><span class=\"line\">gsearch2 = GridSearchCV(estimator = RandomForestClassifier(n_estimators=<span class=\"number\">200</span>),param_grid = param_test2, cv=<span class=\"number\">5</span>)</span><br><span class=\"line\">gsearch2.fit(X_train,y_train)</span><br><span class=\"line\">print( gsearch2.best_params_, gsearch2.best_score_)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#最好的随机森林模型</span></span><br><span class=\"line\">best_rf=RandomForestClassifier(n_estimators=<span class=\"number\">200</span>, max_depth=<span class=\"number\">20</span>, min_samples_split=<span class=\"number\">10</span>) </span><br><span class=\"line\"></span><br><span class=\"line\">best_rf .fit(X_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\">yrfhat = best_rf .predict(X_valid)</span><br><span class=\"line\">feat_importance = best_rf.feature_importances_</span><br><span class=\"line\">rffeat_importance = pd.DataFrame([totalfeatures, random_forest.feature_importances_]).T</span><br><span class=\"line\"></span><br><span class=\"line\">print(<span class=\"string\">'******************随机森林模型**************'</span>)</span><br><span class=\"line\">print(<span class=\"string\">'训练集上的准确率'</span>,best_rf.score(X_train, y_train))</span><br><span class=\"line\">print(<span class=\"string\">'验证集上的准确率'</span>,best_rf.score(X_valid,y_valid))</span><br><span class=\"line\">print(<span class=\"string\">'混淆矩阵\\n'</span>, confusion_matrix(y_valid, yrfhat))</span><br><span class=\"line\">print(<span class=\"string\">'********************************************************'</span>)</span><br><span class=\"line\">print(<span class=\"string\">'最好的随机森林模型的分类报告\\n'</span>, classification_report(y_valid, yrfhat))</span><br><span class=\"line\">print(rffeat_importance.sort_values(by=<span class=\"number\">1</span>, ascending=<span class=\"literal\">False</span>))</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304082741369.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/20200304082759746.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>通过roc比较三种模型性能</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">models = [best_LR, best_DT,best_rf]</span><br><span class=\"line\">modelnames = [<span class=\"string\">'Logistic regression'</span>,  <span class=\"string\">'Random Forest'</span>, <span class=\"string\">'Decison tree'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i, x <span class=\"keyword\">in</span> enumerate(models):</span><br><span class=\"line\">    y_true = y_test</span><br><span class=\"line\">    y_probas = x.predict_proba(X_test)</span><br><span class=\"line\">    ax1 = skplt.metrics.plot_roc(y_true, y_probas, plot_micro=<span class=\"literal\">False</span>, plot_macro=<span class=\"literal\">True</span>, classes_to_plot=[], figsize=(<span class=\"number\">5</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">    plt.axis((<span class=\"number\">-0.01</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">1.1</span>))</span><br><span class=\"line\">    plt.legend([modelnames[i]], loc=<span class=\"string\">'best'</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304082923352.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dtpred=best_DT.predict(X_test)</span><br><span class=\"line\">rfpred=best_rf.predict(X_test)</span><br><span class=\"line\"></span><br><span class=\"line\">dt_score=accuracy_score(y_test,dtpred)</span><br><span class=\"line\">rf_score=accuracy_score(y_test,rfpred)</span><br><span class=\"line\"></span><br><span class=\"line\">print(<span class=\"string\">\"决策树在测试集上准确率为:\"</span>,dt_score)</span><br><span class=\"line\">print(<span class=\"string\">\"随机森林在测试集上准确率为:\"</span>,rf_score)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> dt_score&gt;rf_score:</span><br><span class=\"line\">    print(<span class=\"string\">\"决策树模型是三者中最好的分类模型\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    print(<span class=\"string\">\"随机森林是三者中最好的分类模型\"</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://img-blog.csdnimg.cn/20200304083000622.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/20200304083045336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZWxnaQ==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"5-分析与总结\"><a href=\"#5-分析与总结\" class=\"headerlink\" title=\"5.分析与总结\"></a>5.分析与总结</h2><hr>\n\n<h3 id=\"分析：\"><a href=\"#分析：\" class=\"headerlink\" title=\"分析：\"></a>分析：</h3><p><strong>从上面的条形图中我们可以发现影响自杀率的主要特征是employeecompensation、Selfemployed、Refugees、country、GDPpyear、population</strong></p>\n<p>首先我们的自杀率=自杀人数/总人口数<br>接下来我们就对这几个特征影响自杀率的原因进行分析：</p>\n<ol>\n<li>employeecompensation（工资）当工资低，占开支的百分比较少时，也就意味着生活质量很低，从而自杀率升高；</li>\n<li>Selfemployed（个体经营家庭总人数占比）当个体经营家庭总人数占比高时，就业压力相对较小，所以自杀率较低；</li>\n<li>Refugees（难民人口）当难民人口较多时，难民生存困难，很有可能就因为各种原因堕落消沉从而导致自杀率升高；</li>\n<li>country（国家）发达国家的人民生活节奏快，竞争压力大，失业率高，所以自杀率高；</li>\n<li>GDPpyear（国家的年度生产总值）经济发展快速的国家，也就有更大的就业竞争压力，从而GDPpyear高的国家自杀率高；</li>\n<li>population（人口数量）由于我们计算的是自杀率，从而人口数量也是一个影响因素；当具有相同自杀人数时，人口总数越高，自杀率越低；而人口基数越大，自杀率也会升高。</li>\n</ol>\n<h3 id=\"总结：\"><a href=\"#总结：\" class=\"headerlink\" title=\"总结：\"></a>总结：</h3><p>对于一个国家来说</p>\n<ul>\n<li>当人们工资少，那么自杀率会升高（最重要！！！也说明了物质社会人们对于物质的需求还是很渴望的）</li>\n<li>当每个家庭和睦、家庭氛围好，家庭压力小，那么自杀率会降低</li>\n<li>当难民较多，那么自杀率会升高</li>\n<li>当国家越发达，GDP越高，那么生活节奏飞快，生活成本很高,失业率严重、人际关系紧张等，从而导致自杀率高</li>\n<li>对于人口数量多的国家，自杀人数处于正态分布，当人口数量足够大时，相应的自杀率也就很小</li>\n</ul>\n<p>全球范围内，年龄越大的人群自杀率相对较高。在现在全球人口老龄化的趋势下，这种情况无疑更加严峻。关于老年人群的生活的物质条件需要改善，其心理更需要梳理与关注。而男性比起女性来说社会压力更大，从而自杀率也更大，所以公司也应该定期对职员进行心理疏导。</p>\n<h2 id=\"6-不足与改进：\"><a href=\"#6-不足与改进：\" class=\"headerlink\" title=\"6.不足与改进：\"></a>6.不足与改进：</h2><p><strong>不足：</strong></p>\n<p>从这次数据分析基本得到了结论，也与实际相符合，但是回顾来看，模型依然是过拟合的，我们只能减小过拟合程度；对于网格搜索的超参数由于各种原因限制，我们也无法实验所有的超参数，从而也无法真正得到最优参数与最优模型，得到的只能是相对较好的，泛化能力较强的模型；但是随机森林作为最好的分类模型，虽然它的受噪音影响小，鲁棒性更强，但是如果数据噪音较大也容易过拟合。</p>\n<p><strong>改进：</strong></p>\n<ol>\n<li>我们可以尝试更多的分类模型，比如：SVM、KNN、MLP或者是更复杂的神经网络</li>\n<li>我们可以先对数据特征做处理，比如特征提取（PCA、LDA、SVD），特征提取（Filter、Wrapper、Embedded），或者基于不纯度的减少量作为指标，得到最主要的特征再进行建模</li>\n<li>加入更多的超参数进行搜索，得到更贴近最好的分类模型</li>\n</ol>\n<h1 id=\"最后\"><a href=\"#最后\" class=\"headerlink\" title=\"最后\"></a>最后</h1><p>这个世界有意思的事情还是很多的，稍微别那么在乎物质需求方面，会发现世界的另一面。总之还是积极向上点吧，我继续极限导数微分积分去了。</p>\n","comments":true,"tags":[{"name":"数据分析","slug":"数据分析","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}]},{"title":"关于考研","date":"2020-03-24T10:17:18.000Z","path":"2020/03/24/关于考研/","text":"考研给我的感受虽然我才刚刚开始备考不久，但是我已经感觉到考研的困难了。最大的障碍就是在于自律性，由于疫情这个特殊时期我们不能正常的开学，所以在家能否高效的学习就成了我们这一届考研党分胜负的一个重要因素。 竞争永远都是那么激烈，那么残酷。不能因为看不到别人在努力就轻易放松自己，你看不到别人的努力才是最可怕的。 我有很好的天赋，但是我很多机会都没有好好的去珍惜，这一次我真的不想再错过了，因此我这一个月可以说是“废寝忘食”，而且在家我有的时候就是饿极了才会吃点饼干，其余时间基本都是在看书和做题写笔记，我体会到了初中课文的一句话，“以中有足乐者，不知口体之奉不若人也。盖余之勤且艰若此。”，真的就是这样，看到了姐姐或者是同学在家还有鱼有肉，而我只能吃饼干，但是我想到更多的是如何把这些题做出来，而不是吃什么，对我来说不那么饿就够了。 近期的安排以及复习计划最近就是在看线代，因为线代内容比较少，所以我打算争取四月份之前能把线代看完，这样四月份之后就可以开始刷刷数二的题同时也开始复习408的内容。 结尾我们作为考研党都要首先认识到一件事，我们考研的目的绝对不是为了考上研，如果把考上研当作最后的目标那考上研了又有什么用呢？考研的目的只是为了给我们一个更好的平台，或者说更多的机会，能得到更好的教育学到更多的知识，这样我们才能离我们的人生目标更近一步。最后，我一定会考上华科的！我一定会考上华科的！我一定会考上华科的！","content":"<h1 id=\"考研给我的感受\"><a href=\"#考研给我的感受\" class=\"headerlink\" title=\"考研给我的感受\"></a>考研给我的感受</h1><p>虽然我才刚刚开始备考不久，但是我已经感觉到考研的困难了。最大的障碍就是在于自律性，由于疫情这个特殊时期我们不能正常的开学，所以在家能否高效的学习就成了我们这一届考研党分胜负的一个重要因素。</p>\n<p>竞争永远都是那么激烈，那么残酷。不能因为看不到别人在努力就轻易放松自己，你看不到别人的努力才是最可怕的。</p>\n<p>我有很好的天赋，但是我很多机会都没有好好的去珍惜，这一次我真的不想再错过了，因此我这一个月可以说是“废寝忘食”，而且在家我有的时候就是饿极了才会吃点饼干，其余时间基本都是在看书和做题写笔记，我体会到了初中课文的一句话，“以中有足乐者，不知口体之奉不若人也。盖余之勤且艰若此。”，真的就是这样，看到了姐姐或者是同学在家还有鱼有肉，而我只能吃饼干，但是我想到更多的是如何把这些题做出来，而不是吃什么，对我来说不那么饿就够了。</p>\n<h2 id=\"近期的安排以及复习计划\"><a href=\"#近期的安排以及复习计划\" class=\"headerlink\" title=\"近期的安排以及复习计划\"></a>近期的安排以及复习计划</h2><p>最近就是在看线代，因为线代内容比较少，所以我打算争取四月份之前能把线代看完，这样四月份之后就可以开始刷刷数二的题同时也开始复习408的内容。</p>\n<h2 id=\"结尾\"><a href=\"#结尾\" class=\"headerlink\" title=\"结尾\"></a>结尾</h2><p>我们作为考研党都要首先认识到一件事，我们考研的目的绝对不是为了考上研，如果把考上研当作最后的目标那考上研了又有什么用呢？考研的目的只是为了给我们一个更好的平台，或者说更多的机会，能得到更好的教育学到更多的知识，这样我们才能离我们的人生目标更近一步。最后，我一定会考上华科的！我一定会考上华科的！我一定会考上华科的！</p>\n","comments":true,"tags":[{"name":"作为苦逼的考研党，我想说的一些话","slug":"作为苦逼的考研党，我想说的一些话","permalink":"http://yoursite.com/tags/%E4%BD%9C%E4%B8%BA%E8%8B%A6%E9%80%BC%E7%9A%84%E8%80%83%E7%A0%94%E5%85%9A%EF%BC%8C%E6%88%91%E6%83%B3%E8%AF%B4%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%9D/"}]},{"title":"我的第一篇博客","date":"2020-03-24T08:25:17.000Z","path":"2020/03/24/我的第一篇博客/","text":"很开心，在复习之余还能找点事来休闲自己我一定能考研成功的，冲冲冲！","content":"<h2 id=\"很开心，在复习之余还能找点事来休闲自己\"><a href=\"#很开心，在复习之余还能找点事来休闲自己\" class=\"headerlink\" title=\"很开心，在复习之余还能找点事来休闲自己\"></a>很开心，在复习之余还能找点事来休闲自己</h2><p><strong>我一定能考研成功的，冲冲冲！</strong></p>\n","comments":true,"tags":[{"name":"我打算搭建一个自己的博客，所以这是开头第一篇","slug":"我打算搭建一个自己的博客，所以这是开头第一篇","permalink":"http://yoursite.com/tags/%E6%88%91%E6%89%93%E7%AE%97%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2%EF%BC%8C%E6%89%80%E4%BB%A5%E8%BF%99%E6%98%AF%E5%BC%80%E5%A4%B4%E7%AC%AC%E4%B8%80%E7%AF%87/"}]}],"categories":[],"tags":[{"name":"我想说的","slug":"我想说的","permalink":"http://yoursite.com/tags/%E6%88%91%E6%83%B3%E8%AF%B4%E7%9A%84/"},{"name":"数据分析","slug":"数据分析","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"},{"name":"作为苦逼的考研党，我想说的一些话","slug":"作为苦逼的考研党，我想说的一些话","permalink":"http://yoursite.com/tags/%E4%BD%9C%E4%B8%BA%E8%8B%A6%E9%80%BC%E7%9A%84%E8%80%83%E7%A0%94%E5%85%9A%EF%BC%8C%E6%88%91%E6%83%B3%E8%AF%B4%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%9D/"},{"name":"我打算搭建一个自己的博客，所以这是开头第一篇","slug":"我打算搭建一个自己的博客，所以这是开头第一篇","permalink":"http://yoursite.com/tags/%E6%88%91%E6%89%93%E7%AE%97%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2%EF%BC%8C%E6%89%80%E4%BB%A5%E8%BF%99%E6%98%AF%E5%BC%80%E5%A4%B4%E7%AC%AC%E4%B8%80%E7%AF%87/"}]}